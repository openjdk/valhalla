/*
 * Copyright (c) 1997, 2020, Oracle and/or its affiliates. All rights reserved.
 * Copyright (c) 2014, 2020 Red Hat Inc. All rights reserved.
 * DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.
 *
 * This code is free software; you can redistribute it and/or modify it
 * under the terms of the GNU General Public License version 2 only, as
 * published by the Free Software Foundation.
 *
 * This code is distributed in the hope that it will be useful, but WITHOUT
 * ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or
 * FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General Public License
 * version 2 for more details (a copy is included in the LICENSE file that
 * accompanied this code).
 *
 * You should have received a copy of the GNU General Public License version
 * 2 along with this work; if not, write to the Free Software Foundation,
 * Inc., 51 Franklin St, Fifth Floor, Boston, MA 02110-1301 USA.
 *
 * Please contact Oracle, 500 Oracle Parkway, Redwood Shores, CA 94065 USA
 * or visit www.oracle.com if you need additional information or have any
 * questions.
 */

#include <stdio.h>
#include <sys/types.h>

#include "precompiled.hpp"
#include "asm/assembler.hpp"
#include "asm/assembler.inline.hpp"
#include "interpreter/interpreter.hpp"

#ifndef PRODUCT
const uintptr_t Assembler::asm_bp = 0x00007fffee09ac88;
#endif

#include "compiler/disassembler.hpp"
#include "memory/resourceArea.hpp"
#include "runtime/interfaceSupport.inline.hpp"
#include "runtime/sharedRuntime.hpp"
#include "immediate_aarch64.hpp"

extern "C" void entry(CodeBuffer *cb);

#define __ _masm.
#ifdef PRODUCT
#define BLOCK_COMMENT(str) /* nothing */
#else
#define BLOCK_COMMENT(str) block_comment(str)
#endif

#define BIND(label) bind(label); __ BLOCK_COMMENT(#label ":")

static float unpack(unsigned value);

short Assembler::SIMD_Size_in_bytes[] = {
  // T8B, T16B, T4H, T8H, T2S, T4S, T1D, T2D, T1Q
       8,   16,   8,  16,   8,  16,   8,  16,  16
};

#ifdef ASSERT
static void asm_check(const unsigned int *insns, const unsigned int *insns1, size_t len) {
    bool ok = true;
    for (unsigned int i = 0; i < len; i++) {
      if (insns[i] != insns1[i]) {
        ok = false;
        printf("Ours:\n");
        Disassembler::decode((address)&insns1[i], (address)&insns1[i+1]);
        printf("Theirs:\n");
        Disassembler::decode((address)&insns[i], (address)&insns[i+1]);
        printf("\n");
      }
    }
    assert(ok, "Assembler smoke test failed");
  }

void entry(CodeBuffer *cb) {

  // {
  //   for (int i = 0; i < 256; i+=16)
  //     {
  //    printf("\"%20.20g\", ", unpack(i));
  //    printf("\"%20.20g\", ", unpack(i+1));
  //     }
  //   printf("\n");
  // }

  Assembler _masm(cb);
  address entry = __ pc();

  // Smoke test for assembler

// BEGIN  Generated code -- do not edit
// Generated by aarch64-asmtest.py
    Label back, forth;
    __ bind(back);

// ArithOp
    __ add(r4, r3, r0, Assembler::LSR, 9);             //       add     x4, x3, x0, LSR #9
    __ sub(r8, r29, r4, Assembler::LSL, 17);           //       sub     x8, x29, x4, LSL #17
    __ adds(r7, r27, r23, Assembler::LSL, 17);         //       adds    x7, x27, x23, LSL #17
    __ subs(r6, r15, r9, Assembler::LSR, 41);          //       subs    x6, x15, x9, LSR #41
    __ addw(r12, r3, r16, Assembler::ASR, 23);         //       add     w12, w3, w16, ASR #23
    __ subw(r8, r24, r29, Assembler::LSR, 31);         //       sub     w8, w24, w29, LSR #31
    __ addsw(r7, r28, r15, Assembler::LSL, 7);         //       adds    w7, w28, w15, LSL #7
    __ subsw(r26, r15, r28, Assembler::LSR, 13);       //       subs    w26, w15, w28, LSR #13
    __ andr(r1, r8, r2, Assembler::ASR, 28);           //       and     x1, x8, x2, ASR #28
    __ orr(r19, r27, r12, Assembler::LSR, 10);         //       orr     x19, x27, x12, LSR #10
    __ eor(r4, r11, r10, Assembler::LSR, 59);          //       eor     x4, x11, x10, LSR #59
    __ ands(r5, r17, r2, Assembler::LSL, 28);          //       ands    x5, x17, x2, LSL #28
    __ andw(r28, r15, r12, Assembler::LSR, 13);        //       and     w28, w15, w12, LSR #13
    __ orrw(r14, r21, r25, Assembler::LSR, 16);        //       orr     w14, w21, w25, LSR #16
    __ eorw(r13, r16, r0, Assembler::LSR, 4);          //       eor     w13, w16, w0, LSR #4
    __ andsw(r30, r26, r16, Assembler::LSR, 19);       //       ands    w30, w26, w16, LSR #19
    __ bic(r12, r23, r25, Assembler::LSR, 21);         //       bic     x12, x23, x25, LSR #21
    __ orn(r11, r5, r1, Assembler::LSR, 8);            //       orn     x11, x5, x1, LSR #8
    __ eon(r6, r17, r5, Assembler::ASR, 54);           //       eon     x6, x17, x5, ASR #54
    __ bics(r30, r19, r15, Assembler::ASR, 50);        //       bics    x30, x19, x15, ASR #50
    __ bicw(r15, r6, r27, Assembler::LSR, 6);          //       bic     w15, w6, w27, LSR #6
    __ ornw(r22, r3, r6, Assembler::ASR, 4);           //       orn     w22, w3, w6, ASR #4
    __ eonw(r2, r4, r23, Assembler::ASR, 5);           //       eon     w2, w4, w23, ASR #5
    __ bicsw(r2, r5, r30, Assembler::ASR, 19);         //       bics    w2, w5, w30, ASR #19

// AddSubImmOp
    __ addw(r12, r16, 900u);                           //       add     w12, w16, #900
    __ addsw(r11, r8, 680u);                           //       adds    w11, w8, #680
    __ subw(r8, r7, 44u);                              //       sub     w8, w7, #44
    __ subsw(r8, r15, 994u);                           //       subs    w8, w15, #994
    __ add(r0, r26, 9u);                               //       add     x0, x26, #9
    __ adds(r27, r18, 929u);                           //       adds    x27, x18, #929
    __ sub(r18, r8, 300u);                             //       sub     x18, x8, #300
    __ subs(r20, r13, 583u);                           //       subs    x20, x13, #583

// LogicalImmOp
    __ andw(r29, r19, 8388600ull);                     //       and     w29, w19, #0x7ffff8
    __ orrw(r14, r3, 4294965263ull);                   //       orr     w14, w3, #0xfffff80f
    __ eorw(r14, r29, 1048576ull);                     //       eor     w14, w29, #0x100000
    __ andsw(r24, r17, 134217216ull);                  //       ands    w24, w17, #0x7fffe00
    __ andr(r17, r3, 13835058603964235903ull);         //       and     x17, x3, #0xc000007fc000007f
    __ orr(r7, r14, 18158513714670600195ull);          //       orr     x7, x14, #0xfc000003fc000003
    __ eor(r5, r26, 17870287719452639231ull);          //       eor     x5, x26, #0xf80003ffffffffff
    __ ands(r26, r21, 9205357640488583168ull);         //       ands    x26, x21, #0x7fc000007fc00000

// AbsOp
    __ b(__ pc());                                     //       b       .
    __ b(back);                                        //       b       back
    __ b(forth);                                       //       b       forth
    __ bl(__ pc());                                    //       bl      .
    __ bl(back);                                       //       bl      back
    __ bl(forth);                                      //       bl      forth

// RegAndAbsOp
    __ cbzw(r0, __ pc());                              //       cbz     w0, .
    __ cbzw(r0, back);                                 //       cbz     w0, back
    __ cbzw(r0, forth);                                //       cbz     w0, forth
    __ cbnzw(r11, __ pc());                            //       cbnz    w11, .
    __ cbnzw(r11, back);                               //       cbnz    w11, back
    __ cbnzw(r11, forth);                              //       cbnz    w11, forth
    __ cbz(r21, __ pc());                              //       cbz     x21, .
    __ cbz(r21, back);                                 //       cbz     x21, back
    __ cbz(r21, forth);                                //       cbz     x21, forth
    __ cbnz(r8, __ pc());                              //       cbnz    x8, .
    __ cbnz(r8, back);                                 //       cbnz    x8, back
    __ cbnz(r8, forth);                                //       cbnz    x8, forth
    __ adr(r11, __ pc());                              //       adr     x11, .
    __ adr(r11, back);                                 //       adr     x11, back
    __ adr(r11, forth);                                //       adr     x11, forth
    __ _adrp(r0, __ pc());                             //       adrp    x0, .

// RegImmAbsOp
    __ tbz(r5, 2, __ pc());                            //       tbz     x5, #2, .
    __ tbz(r5, 2, back);                               //       tbz     x5, #2, back
    __ tbz(r5, 2, forth);                              //       tbz     x5, #2, forth
    __ tbnz(r22, 4, __ pc());                          //       tbnz    x22, #4, .
    __ tbnz(r22, 4, back);                             //       tbnz    x22, #4, back
    __ tbnz(r22, 4, forth);                            //       tbnz    x22, #4, forth

// MoveWideImmOp
    __ movnw(r22, 11702, 16);                          //       movn    w22, #11702, lsl 16
    __ movzw(r20, 27561, 16);                          //       movz    w20, #27561, lsl 16
    __ movkw(r30, 30436, 0);                           //       movk    w30, #30436, lsl 0
    __ movn(r27, 29470, 32);                           //       movn    x27, #29470, lsl 32
    __ movz(r1, 7779, 48);                             //       movz    x1, #7779, lsl 48
    __ movk(r9, 3765, 16);                             //       movk    x9, #3765, lsl 16

// BitfieldOp
    __ sbfm(r28, r28, 21, 28);                         //       sbfm    x28, x28, #21, #28
    __ bfmw(r15, r4, 8, 2);                            //       bfm     w15, w4, #8, #2
    __ ubfmw(r21, r9, 23, 16);                         //       ubfm    w21, w9, #23, #16
    __ sbfm(r14, r27, 26, 21);                         //       sbfm    x14, x27, #26, #21
    __ bfm(r19, r6, 28, 29);                           //       bfm     x19, x6, #28, #29
    __ ubfm(r11, r22, 16, 2);                          //       ubfm    x11, x22, #16, #2

// ExtractOp
    __ extrw(r7, r22, r1, 28);                         //       extr    w7, w22, w1, #28
    __ extr(r21, r27, r14, 54);                        //       extr    x21, x27, x14, #54

// CondBranchOp
    __ br(Assembler::EQ, __ pc());                     //       b.EQ    .
    __ br(Assembler::EQ, back);                        //       b.EQ    back
    __ br(Assembler::EQ, forth);                       //       b.EQ    forth
    __ br(Assembler::NE, __ pc());                     //       b.NE    .
    __ br(Assembler::NE, back);                        //       b.NE    back
    __ br(Assembler::NE, forth);                       //       b.NE    forth
    __ br(Assembler::HS, __ pc());                     //       b.HS    .
    __ br(Assembler::HS, back);                        //       b.HS    back
    __ br(Assembler::HS, forth);                       //       b.HS    forth
    __ br(Assembler::CS, __ pc());                     //       b.CS    .
    __ br(Assembler::CS, back);                        //       b.CS    back
    __ br(Assembler::CS, forth);                       //       b.CS    forth
    __ br(Assembler::LO, __ pc());                     //       b.LO    .
    __ br(Assembler::LO, back);                        //       b.LO    back
    __ br(Assembler::LO, forth);                       //       b.LO    forth
    __ br(Assembler::CC, __ pc());                     //       b.CC    .
    __ br(Assembler::CC, back);                        //       b.CC    back
    __ br(Assembler::CC, forth);                       //       b.CC    forth
    __ br(Assembler::MI, __ pc());                     //       b.MI    .
    __ br(Assembler::MI, back);                        //       b.MI    back
    __ br(Assembler::MI, forth);                       //       b.MI    forth
    __ br(Assembler::PL, __ pc());                     //       b.PL    .
    __ br(Assembler::PL, back);                        //       b.PL    back
    __ br(Assembler::PL, forth);                       //       b.PL    forth
    __ br(Assembler::VS, __ pc());                     //       b.VS    .
    __ br(Assembler::VS, back);                        //       b.VS    back
    __ br(Assembler::VS, forth);                       //       b.VS    forth
    __ br(Assembler::VC, __ pc());                     //       b.VC    .
    __ br(Assembler::VC, back);                        //       b.VC    back
    __ br(Assembler::VC, forth);                       //       b.VC    forth
    __ br(Assembler::HI, __ pc());                     //       b.HI    .
    __ br(Assembler::HI, back);                        //       b.HI    back
    __ br(Assembler::HI, forth);                       //       b.HI    forth
    __ br(Assembler::LS, __ pc());                     //       b.LS    .
    __ br(Assembler::LS, back);                        //       b.LS    back
    __ br(Assembler::LS, forth);                       //       b.LS    forth
    __ br(Assembler::GE, __ pc());                     //       b.GE    .
    __ br(Assembler::GE, back);                        //       b.GE    back
    __ br(Assembler::GE, forth);                       //       b.GE    forth
    __ br(Assembler::LT, __ pc());                     //       b.LT    .
    __ br(Assembler::LT, back);                        //       b.LT    back
    __ br(Assembler::LT, forth);                       //       b.LT    forth
    __ br(Assembler::GT, __ pc());                     //       b.GT    .
    __ br(Assembler::GT, back);                        //       b.GT    back
    __ br(Assembler::GT, forth);                       //       b.GT    forth
    __ br(Assembler::LE, __ pc());                     //       b.LE    .
    __ br(Assembler::LE, back);                        //       b.LE    back
    __ br(Assembler::LE, forth);                       //       b.LE    forth
    __ br(Assembler::AL, __ pc());                     //       b.AL    .
    __ br(Assembler::AL, back);                        //       b.AL    back
    __ br(Assembler::AL, forth);                       //       b.AL    forth
    __ br(Assembler::NV, __ pc());                     //       b.NV    .
    __ br(Assembler::NV, back);                        //       b.NV    back
    __ br(Assembler::NV, forth);                       //       b.NV    forth

// ImmOp
    __ svc(32085);                                     //       svc     #32085
    __ hvc(4810);                                      //       hvc     #4810
    __ smc(21956);                                     //       smc     #21956
    __ brk(21112);                                     //       brk     #21112
    __ hlt(15915);                                     //       hlt     #15915

// Op
    __ nop();                                          //       nop
    __ eret();                                         //       eret
    __ drps();                                         //       drps
    __ isb();                                          //       isb

// SystemOp
    __ dsb(Assembler::ISHST);                          //       dsb     ISHST
    __ dmb(Assembler::ISHST);                          //       dmb     ISHST

// OneRegOp
    __ br(r17);                                        //       br      x17
    __ blr(r0);                                        //       blr     x0

// LoadStoreExclusiveOp
    __ stxr(r3, r7, r12);                              //       stxr    w3, x7, [x12]
    __ stlxr(r16, r13, r18);                           //       stlxr   w16, x13, [x18]
    __ ldxr(r11, r30);                                 //       ldxr    x11, [x30]
    __ ldaxr(r21, r3);                                 //       ldaxr   x21, [x3]
    __ stlr(r22, r26);                                 //       stlr    x22, [x26]
    __ ldar(r2, r27);                                  //       ldar    x2, [x27]

// LoadStoreExclusiveOp
    __ stxrw(r20, r15, r2);                            //       stxr    w20, w15, [x2]
    __ stlxrw(r11, r8, r13);                           //       stlxr   w11, w8, [x13]
    __ ldxrw(r16, r26);                                //       ldxr    w16, [x26]
    __ ldaxrw(r27, r11);                               //       ldaxr   w27, [x11]
    __ stlrw(r30, r4);                                 //       stlr    w30, [x4]
    __ ldarw(r2, r11);                                 //       ldar    w2, [x11]

// LoadStoreExclusiveOp
    __ stxrh(r22, r27, r18);                           //       stxrh   w22, w27, [x18]
    __ stlxrh(r25, r10, r23);                          //       stlxrh  w25, w10, [x23]
    __ ldxrh(r13, r30);                                //       ldxrh   w13, [x30]
    __ ldaxrh(r13, r2);                                //       ldaxrh  w13, [x2]
    __ stlrh(r2, r24);                                 //       stlrh   w2, [x24]
    __ ldarh(r25, r23);                                //       ldarh   w25, [x23]

// LoadStoreExclusiveOp
    __ stxrb(r13, r0, r29);                            //       stxrb   w13, w0, [x29]
    __ stlxrb(r8, r20, r6);                            //       stlxrb  w8, w20, [x6]
    __ ldxrb(r15, r5);                                 //       ldxrb   w15, [x5]
    __ ldaxrb(r0, r10);                                //       ldaxrb  w0, [x10]
    __ stlrb(r12, r26);                                //       stlrb   w12, [x26]
    __ ldarb(r11, r2);                                 //       ldarb   w11, [x2]

// LoadStoreExclusiveOp
    __ ldxp(r23, r17, r9);                             //       ldxp    x23, x17, [x9]
    __ ldaxp(r1, r7, r13);                             //       ldaxp   x1, x7, [x13]
    __ stxp(r7, r0, r11, r29);                         //       stxp    w7, x0, x11, [x29]
    __ stlxp(r25, r22, r5, r11);                       //       stlxp   w25, x22, x5, [x11]

// LoadStoreExclusiveOp
    __ ldxpw(r7, r6, r27);                             //       ldxp    w7, w6, [x27]
    __ ldaxpw(r7, r2, r24);                            //       ldaxp   w7, w2, [x24]
    __ stxpw(r6, r5, r30, r19);                        //       stxp    w6, w5, w30, [x19]
    __ stlxpw(r2, r29, r7, r18);                       //       stlxp   w2, w29, w7, [x18]

// base_plus_unscaled_offset
// LoadStoreOp
    __ str(r29, Address(r20, -183));                   //       str     x29, [x20, -183]
    __ strw(r6, Address(r13, -39));                    //       str     w6, [x13, -39]
    __ strb(r9, Address(r5, -11));                     //       strb    w9, [x5, -11]
    __ strh(r22, Address(r8, 21));                     //       strh    w22, [x8, 21]
    __ ldr(r1, Address(r29, -81));                     //       ldr     x1, [x29, -81]
    __ ldrw(r20, Address(r29, -27));                   //       ldr     w20, [x29, -27]
    __ ldrb(r15, Address(r12, -8));                    //       ldrb    w15, [x12, -8]
    __ ldrh(r9, Address(r7, -62));                     //       ldrh    w9, [x7, -62]
    __ ldrsb(r23, Address(r13, -9));                   //       ldrsb   x23, [x13, -9]
    __ ldrsh(r18, Address(r13, 30));                   //       ldrsh   x18, [x13, 30]
    __ ldrshw(r17, Address(r30, 26));                  //       ldrsh   w17, [x30, 26]
    __ ldrsw(r21, Address(r14, -125));                 //       ldrsw   x21, [x14, -125]
    __ ldrd(v21, Address(r13, 59));                    //       ldr     d21, [x13, 59]
    __ ldrs(v21, Address(r8, 63));                     //       ldr     s21, [x8, 63]
    __ strd(v22, Address(r24, 53));                    //       str     d22, [x24, 53]
    __ strs(v26, Address(r0, 21));                     //       str     s26, [x0, 21]

// pre
// LoadStoreOp
    __ str(r23, Address(__ pre(r22, -215)));           //       str     x23, [x22, -215]!
    __ strw(r30, Address(__ pre(r29, -3)));            //       str     w30, [x29, -3]!
    __ strb(r2, Address(__ pre(r7, -18)));             //       strb    w2, [x7, -18]!
    __ strh(r23, Address(__ pre(r12, 19)));            //       strh    w23, [x12, 19]!
    __ ldr(r18, Address(__ pre(r4, -210)));            //       ldr     x18, [x4, -210]!
    __ ldrw(r19, Address(__ pre(r30, -71)));           //       ldr     w19, [x30, -71]!
    __ ldrb(r17, Address(__ pre(r20, -11)));           //       ldrb    w17, [x20, -11]!
    __ ldrh(r9, Address(__ pre(r14, -64)));            //       ldrh    w9, [x14, -64]!
    __ ldrsb(r6, Address(__ pre(r3, 11)));             //       ldrsb   x6, [x3, 11]!
    __ ldrsh(r11, Address(__ pre(r22, -6)));           //       ldrsh   x11, [x22, -6]!
    __ ldrshw(r6, Address(__ pre(r11, -27)));          //       ldrsh   w6, [x11, -27]!
    __ ldrsw(r25, Address(__ pre(r18, 54)));           //       ldrsw   x25, [x18, 54]!
    __ ldrd(v21, Address(__ pre(r23, -8)));            //       ldr     d21, [x23, -8]!
    __ ldrs(v30, Address(__ pre(r10, -39)));           //       ldr     s30, [x10, -39]!
    __ strd(v2, Address(__ pre(r1, -129)));            //       str     d2, [x1, -129]!
    __ strs(v26, Address(__ pre(r0, 1)));              //       str     s26, [x0, 1]!

// post
// LoadStoreOp
    __ str(r9, Address(__ post(r26, -99)));            //       str     x9, [x26], -99
    __ strw(r9, Address(__ post(r14, 62)));            //       str     w9, [x14], 62
    __ strb(r30, Address(__ post(r26, -30)));          //       strb    w30, [x26], -30
    __ strh(r28, Address(__ post(r16, 11)));           //       strh    w28, [x16], 11
    __ ldr(r29, Address(__ post(r26, 77)));            //       ldr     x29, [x26], 77
    __ ldrw(r0, Address(__ post(r23, 53)));            //       ldr     w0, [x23], 53
    __ ldrb(r7, Address(__ post(r21, -18)));           //       ldrb    w7, [x21], -18
    __ ldrh(r24, Address(__ post(r13, 24)));           //       ldrh    w24, [x13], 24
    __ ldrsb(r1, Address(__ post(r8, -17)));           //       ldrsb   x1, [x8], -17
    __ ldrsh(r17, Address(__ post(r27, -34)));         //       ldrsh   x17, [x27], -34
    __ ldrshw(r21, Address(__ post(r1, -26)));         //       ldrsh   w21, [x1], -26
    __ ldrsw(r6, Address(__ post(r21, 0)));            //       ldrsw   x6, [x21], 0
    __ ldrd(v5, Address(__ post(r3, 58)));             //       ldr     d5, [x3], 58
    __ ldrs(v7, Address(__ post(r19, -80)));           //       ldr     s7, [x19], -80
    __ strd(v1, Address(__ post(r16, 27)));            //       str     d1, [x16], 27
    __ strs(v7, Address(__ post(r25, 62)));            //       str     s7, [x25], 62

// base_plus_reg
// LoadStoreOp
    __ str(r13, Address(r3, r30, Address::uxtw(3)));   //       str     x13, [x3, w30, uxtw #3]
    __ strw(r17, Address(r3, r1, Address::sxtx(0)));   //       str     w17, [x3, x1, sxtx #0]
    __ strb(r23, Address(r19, r27, Address::lsl(0)));  //       strb    w23, [x19, x27, lsl #0]
    __ strh(r5, Address(r20, r10, Address::uxtw(1)));  //       strh    w5, [x20, w10, uxtw #1]
    __ ldr(r29, Address(r2, r16, Address::sxtw(3)));   //       ldr     x29, [x2, w16, sxtw #3]
    __ ldrw(r16, Address(r17, r21, Address::sxtx(2))); //       ldr     w16, [x17, x21, sxtx #2]
    __ ldrb(r10, Address(r16, r16, Address::uxtw(0))); //       ldrb    w10, [x16, w16, uxtw #0]
    __ ldrh(r23, Address(r27, r26, Address::sxtw(1))); //       ldrh    w23, [x27, w26, sxtw #1]
    __ ldrsb(r13, Address(r0, r7, Address::lsl(0)));   //       ldrsb   x13, [x0, x7, lsl #0]
    __ ldrsh(r15, Address(r5, r18, Address::uxtw(0))); //       ldrsh   x15, [x5, w18, uxtw #0]
    __ ldrshw(r18, Address(r20, r18, Address::lsl(1))); //      ldrsh   w18, [x20, x18, lsl #1]
    __ ldrsw(r30, Address(r14, r17, Address::uxtw(0))); //      ldrsw   x30, [x14, w17, uxtw #0]
    __ ldrd(v19, Address(r6, r26, Address::uxtw(3)));  //       ldr     d19, [x6, w26, uxtw #3]
    __ ldrs(v30, Address(r23, r2, Address::sxtw(0)));  //       ldr     s30, [x23, w2, sxtw #0]
    __ strd(v27, Address(r22, r7, Address::uxtw(0)));  //       str     d27, [x22, w7, uxtw #0]
    __ strs(v9, Address(r24, r26, Address::sxtx(2)));  //       str     s9, [x24, x26, sxtx #2]

// base_plus_scaled_offset
// LoadStoreOp
    __ str(r14, Address(r28, 16104));                  //       str     x14, [x28, 16104]
    __ strw(r16, Address(r13, 7864));                  //       str     w16, [x13, 7864]
    __ strb(r20, Address(r27, 1562));                  //       strb    w20, [x27, 1562]
    __ strh(r16, Address(r7, 3268));                   //       strh    w16, [x7, 3268]
    __ ldr(r5, Address(r21, 15512));                   //       ldr     x5, [x21, 15512]
    __ ldrw(r0, Address(r8, 7656));                    //       ldr     w0, [x8, 7656]
    __ ldrb(r1, Address(r7, 2020));                    //       ldrb    w1, [x7, 2020]
    __ ldrh(r1, Address(r14, 3294));                   //       ldrh    w1, [x14, 3294]
    __ ldrsb(r6, Address(r25, 1766));                  //       ldrsb   x6, [x25, 1766]
    __ ldrsh(r9, Address(r16, 3248));                  //       ldrsh   x9, [x16, 3248]
    __ ldrshw(r27, Address(r4, 3608));                 //       ldrsh   w27, [x4, 3608]
    __ ldrsw(r2, Address(r16, 7308));                  //       ldrsw   x2, [x16, 7308]
    __ ldrd(v5, Address(r26, 16192));                  //       ldr     d5, [x26, 16192]
    __ ldrs(v19, Address(r13, 7932));                  //       ldr     s19, [x13, 7932]
    __ strd(v22, Address(r7, 13376));                  //       str     d22, [x7, 13376]
    __ strs(v8, Address(r9, 7816));                    //       str     s8, [x9, 7816]

// pcrel
// LoadStoreOp
    __ ldr(r26, back);                                 //       ldr     x26, back
    __ ldrw(r12, back);                                //       ldr     w12, back

// LoadStoreOp
    __ prfm(Address(r10, 47));                         //       prfm    PLDL1KEEP, [x10, 47]

// LoadStoreOp
    __ prfm(forth);                                    //       prfm    PLDL1KEEP, forth

// LoadStoreOp
    __ prfm(Address(r21, r20, Address::lsl(3)));       //       prfm    PLDL1KEEP, [x21, x20, lsl #3]

// LoadStoreOp
    __ prfm(Address(r13, 15776));                      //       prfm    PLDL1KEEP, [x13, 15776]

// AddSubCarryOp
    __ adcw(r26, r8, r3);                              //       adc     w26, w8, w3
    __ adcsw(r9, r30, r7);                             //       adcs    w9, w30, w7
    __ sbcw(r24, r15, r11);                            //       sbc     w24, w15, w11
    __ sbcsw(r4, r21, r11);                            //       sbcs    w4, w21, w11
    __ adc(r15, r17, r30);                             //       adc     x15, x17, x30
    __ adcs(r6, r15, r16);                             //       adcs    x6, x15, x16
    __ sbc(r1, r2, r10);                               //       sbc     x1, x2, x10
    __ sbcs(r9, r4, r11);                              //       sbcs    x9, x4, x11

// AddSubExtendedOp
    __ addw(r23, r29, r17, ext::uxtx, 1);              //       add     w23, w29, w17, uxtx #1
    __ addsw(r15, r11, r11, ext::sxtx, 3);             //       adds    w15, w11, w11, sxtx #3
    __ sub(r2, r30, r7, ext::uxtw, 4);                 //       sub     x2, x30, x7, uxtw #4
    __ subsw(r30, r19, r26, ext::sxtb, 1);             //       subs    w30, w19, w26, sxtb #1
    __ add(r2, r0, r12, ext::uxtx, 3);                 //       add     x2, x0, x12, uxtx #3
    __ adds(r14, r1, r16, ext::sxtb, 4);               //       adds    x14, x1, x16, sxtb #4
    __ sub(r15, r22, r23, ext::sxtb, 3);               //       sub     x15, x22, x23, sxtb #3
    __ subs(r0, r4, r28, ext::uxtw, 1);                //       subs    x0, x4, x28, uxtw #1

// ConditionalCompareOp
    __ ccmnw(r5, r18, 11u, Assembler::CS);             //       ccmn    w5, w18, #11, CS
    __ ccmpw(r18, r21, 8u, Assembler::HS);             //       ccmp    w18, w21, #8, HS
    __ ccmn(r15, r17, 15u, Assembler::CC);             //       ccmn    x15, x17, #15, CC
    __ ccmp(r13, r23, 6u, Assembler::NE);              //       ccmp    x13, x23, #6, NE

// ConditionalCompareImmedOp
    __ ccmnw(r28, 9, 15, Assembler::CC);               //       ccmn    w28, #9, #15, CC
    __ ccmpw(r14, 12, 9, Assembler::LS);               //       ccmp    w14, #12, #9, LS
    __ ccmn(r22, 6, 2, Assembler::LO);                 //       ccmn    x22, #6, #2, LO
    __ ccmp(r21, 12, 0, Assembler::MI);                //       ccmp    x21, #12, #0, MI

// ConditionalSelectOp
    __ cselw(r14, r21, r28, Assembler::GT);            //       csel    w14, w21, w28, GT
    __ csincw(r25, r14, r17, Assembler::GT);           //       csinc   w25, w14, w17, GT
    __ csinvw(r17, r6, r25, Assembler::HS);            //       csinv   w17, w6, w25, HS
    __ csnegw(r21, r2, r14, Assembler::HS);            //       csneg   w21, w2, w14, HS
    __ csel(r3, r11, r17, Assembler::HS);              //       csel    x3, x11, x17, HS
    __ csinc(r27, r30, r27, Assembler::HS);            //       csinc   x27, x30, x27, HS
    __ csinv(r0, r15, r5, Assembler::HI);              //       csinv   x0, x15, x5, HI
    __ csneg(r2, r11, r8, Assembler::CS);              //       csneg   x2, x11, x8, CS

// TwoRegOp
    __ rbitw(r2, r19);                                 //       rbit    w2, w19
    __ rev16w(r22, r12);                               //       rev16   w22, w12
    __ revw(r5, r22);                                  //       rev     w5, w22
    __ clzw(r3, r27);                                  //       clz     w3, w27
    __ clsw(r18, r4);                                  //       cls     w18, w4
    __ rbit(r22, r27);                                 //       rbit    x22, x27
    __ rev16(r12, r10);                                //       rev16   x12, x10
    __ rev32(r5, r4);                                  //       rev32   x5, x4
    __ rev(r22, r10);                                  //       rev     x22, x10
    __ clz(r13, r7);                                   //       clz     x13, x7
    __ cls(r6, r10);                                   //       cls     x6, x10

// ThreeRegOp
    __ udivw(r2, r16, r28);                            //       udiv    w2, w16, w28
    __ sdivw(r8, r23, r8);                             //       sdiv    w8, w23, w8
    __ lslvw(r18, r17, r14);                           //       lslv    w18, w17, w14
    __ lsrvw(r30, r25, r22);                           //       lsrv    w30, w25, w22
    __ asrvw(r16, r2, r5);                             //       asrv    w16, w2, w5
    __ rorvw(r15, r28, r0);                            //       rorv    w15, w28, w0
    __ udiv(r13, r20, r1);                             //       udiv    x13, x20, x1
    __ sdiv(r28, r30, r18);                            //       sdiv    x28, x30, x18
    __ lslv(r17, r28, r9);                             //       lslv    x17, x28, x9
    __ lsrv(r18, r13, r4);                             //       lsrv    x18, x13, x4
    __ asrv(r12, r24, r16);                            //       asrv    x12, x24, x16
    __ rorv(r14, r9, r24);                             //       rorv    x14, x9, x24
    __ umulh(r20, r4, r24);                            //       umulh   x20, x4, x24
    __ smulh(r18, r5, r28);                            //       smulh   x18, x5, x28

// FourRegMulOp
    __ maddw(r19, r29, r17, r18);                      //       madd    w19, w29, w17, w18
    __ msubw(r14, r22, r15, r19);                      //       msub    w14, w22, w15, w19
    __ madd(r12, r5, r1, r8);                          //       madd    x12, x5, x1, x8
    __ msub(r22, r18, r11, r16);                       //       msub    x22, x18, x11, x16
    __ smaddl(r0, r11, r12, r30);                      //       smaddl  x0, w11, w12, x30
    __ smsubl(r19, r8, r13, r12);                      //       smsubl  x19, w8, w13, x12
    __ umaddl(r13, r30, r17, r5);                      //       umaddl  x13, w30, w17, x5
    __ umsubl(r16, r12, r23, r9);                      //       umsubl  x16, w12, w23, x9

// ThreeRegFloatOp
    __ fmuls(v6, v20, v0);                             //       fmul    s6, s20, s0
    __ fdivs(v21, v6, v15);                            //       fdiv    s21, s6, s15
    __ fadds(v24, v9, v25);                            //       fadd    s24, s9, s25
    __ fsubs(v9, v24, v18);                            //       fsub    s9, s24, s18
    __ fmuls(v26, v24, v10);                           //       fmul    s26, s24, s10
    __ fmuld(v12, v20, v0);                            //       fmul    d12, d20, d0
    __ fdivd(v12, v15, v16);                           //       fdiv    d12, d15, d16
    __ faddd(v24, v6, v29);                            //       fadd    d24, d6, d29
    __ fsubd(v24, v6, v14);                            //       fsub    d24, d6, d14
    __ fmuld(v21, v29, v15);                           //       fmul    d21, d29, d15

// FourRegFloatOp
    __ fmadds(v9, v25, v1, v29);                       //       fmadd   s9, s25, s1, s29
    __ fmsubs(v13, v20, v10, v29);                     //       fmsub   s13, s20, s10, s29
    __ fnmadds(v28, v11, v11, v7);                     //       fnmadd  s28, s11, s11, s7
    __ fnmadds(v7, v28, v21, v1);                      //       fnmadd  s7, s28, s21, s1
    __ fmaddd(v30, v29, v15, v1);                      //       fmadd   d30, d29, d15, d1
    __ fmsubd(v12, v8, v27, v26);                      //       fmsub   d12, d8, d27, d26
    __ fnmaddd(v17, v24, v11, v25);                    //       fnmadd  d17, d24, d11, d25
    __ fnmaddd(v30, v1, v8, v0);                       //       fnmadd  d30, d1, d8, d0

// TwoRegFloatOp
    __ fmovs(v1, v5);                                  //       fmov    s1, s5
    __ fabss(v6, v19);                                 //       fabs    s6, s19
    __ fnegs(v4, v0);                                  //       fneg    s4, s0
    __ fsqrts(v9, v10);                                //       fsqrt   s9, s10
    __ fcvts(v20, v14);                                //       fcvt    d20, s14
    __ fmovd(v0, v19);                                 //       fmov    d0, d19
    __ fabsd(v30, v18);                                //       fabs    d30, d18
    __ fnegd(v0, v8);                                  //       fneg    d0, d8
    __ fsqrtd(v0, v8);                                 //       fsqrt   d0, d8
    __ fcvtd(v14, v30);                                //       fcvt    s14, d30

// FloatConvertOp
    __ fcvtzsw(r19, v22);                              //       fcvtzs  w19, s22
    __ fcvtzs(r17, v10);                               //       fcvtzs  x17, s10
    __ fcvtzdw(r27, v21);                              //       fcvtzs  w27, d21
    __ fcvtzd(r7, v4);                                 //       fcvtzs  x7, d4
    __ scvtfws(v30, r25);                              //       scvtf   s30, w25
    __ scvtfs(v25, r16);                               //       scvtf   s25, x16
    __ scvtfwd(v9, r26);                               //       scvtf   d9, w26
    __ scvtfd(v7, r0);                                 //       scvtf   d7, x0
    __ fmovs(r0, v15);                                 //       fmov    w0, s15
    __ fmovd(r11, v4);                                 //       fmov    x11, d4
    __ fmovs(v30, r15);                                //       fmov    s30, w15
    __ fmovd(v2, r23);                                 //       fmov    d2, x23

// TwoRegFloatOp
    __ fcmps(v14, v10);                                //       fcmp    s14, s10
    __ fcmpd(v30, v0);                                 //       fcmp    d30, d0
    __ fcmps(v11, 0.0);                                //       fcmp    s11, #0.0
    __ fcmpd(v24, 0.0);                                //       fcmp    d24, #0.0

// LoadStorePairOp
    __ stpw(r28, r16, Address(r1, -240));              //       stp     w28, w16, [x1, #-240]
    __ ldpw(r23, r21, Address(r14, 96));               //       ldp     w23, w21, [x14, #96]
    __ ldpsw(r0, r24, Address(r7, -64));               //       ldpsw   x0, x24, [x7, #-64]
    __ stp(r21, r20, Address(r16, 128));               //       stp     x21, x20, [x16, #128]
    __ ldp(r1, r3, Address(r26, -112));                //       ldp     x1, x3, [x26, #-112]

// LoadStorePairOp
    __ stpw(r12, r14, Address(__ pre(r10, -240)));     //       stp     w12, w14, [x10, #-240]!
    __ ldpw(r3, r0, Address(__ pre(r7, -240)));        //       ldp     w3, w0, [x7, #-240]!
    __ ldpsw(r26, r24, Address(__ pre(r5, -208)));     //       ldpsw   x26, x24, [x5, #-208]!
    __ stp(r16, r22, Address(__ pre(r8, -160)));       //       stp     x16, x22, [x8, #-160]!
    __ ldp(r26, r4, Address(__ pre(r15, -144)));       //       ldp     x26, x4, [x15, #-144]!

// LoadStorePairOp
    __ stpw(r9, r28, Address(__ post(r29, 112)));      //       stp     w9, w28, [x29], #112
    __ ldpw(r8, r5, Address(__ post(r3, 64)));         //       ldp     w8, w5, [x3], #64
    __ ldpsw(r30, r4, Address(__ post(r12, -208)));    //       ldpsw   x30, x4, [x12], #-208
    __ stp(r14, r30, Address(__ post(r16, -160)));     //       stp     x14, x30, [x16], #-160
    __ ldp(r27, r22, Address(__ post(r9, -208)));      //       ldp     x27, x22, [x9], #-208

// LoadStorePairOp
    __ stnpw(r26, r21, Address(r24, -256));            //       stnp    w26, w21, [x24, #-256]
    __ ldnpw(r20, r9, Address(r15, -48));              //       ldnp    w20, w9, [x15, #-48]
    __ stnp(r15, r26, Address(r13, -240));             //       stnp    x15, x26, [x13, #-240]
    __ ldnp(r5, r26, Address(r5, 16));                 //       ldnp    x5, x26, [x5, #16]

// LdStSIMDOp
    __ ld1(v19, __ T8B, Address(r26));                 //       ld1     {v19.8B}, [x26]
    __ ld1(v1, v2, __ T16B, Address(__ post(r14, 32))); //      ld1     {v1.16B, v2.16B}, [x14], 32
    __ ld1(v29, v30, v31, __ T1D, Address(__ post(r24, r25))); //       ld1     {v29.1D, v30.1D, v31.1D}, [x24], x25
    __ ld1(v20, v21, v22, v23, __ T8H, Address(__ post(r0, 64))); //    ld1     {v20.8H, v21.8H, v22.8H, v23.8H}, [x0], 64
    __ ld1r(v25, __ T8B, Address(r27));                //       ld1r    {v25.8B}, [x27]
    __ ld1r(v30, __ T4S, Address(__ post(r26, 4)));    //       ld1r    {v30.4S}, [x26], 4
    __ ld1r(v9, __ T1D, Address(__ post(r21, r10)));   //       ld1r    {v9.1D}, [x21], x10
    __ ld2(v2, v3, __ T2D, Address(r14));              //       ld2     {v2.2D, v3.2D}, [x14]
    __ ld2(v14, v15, __ T4H, Address(__ post(r18, 16))); //     ld2     {v14.4H, v15.4H}, [x18], 16
    __ ld2r(v4, v5, __ T16B, Address(r0));             //       ld2r    {v4.16B, v5.16B}, [x0]
    __ ld2r(v18, v19, __ T2S, Address(__ post(r1, 8))); //      ld2r    {v18.2S, v19.2S}, [x1], 8
    __ ld2r(v26, v27, __ T2D, Address(__ post(r0, r27))); //    ld2r    {v26.2D, v27.2D}, [x0], x27
    __ ld3(v7, v8, v9, __ T4S, Address(__ post(r22, r3))); //   ld3     {v7.4S, v8.4S, v9.4S}, [x22], x3
    __ ld3(v5, v6, v7, __ T2S, Address(r21));          //       ld3     {v5.2S, v6.2S, v7.2S}, [x21]
    __ ld3r(v30, v31, v0, __ T8H, Address(r7));        //       ld3r    {v30.8H, v31.8H, v0.8H}, [x7]
    __ ld3r(v7, v8, v9, __ T4S, Address(__ post(r23, 12))); //  ld3r    {v7.4S, v8.4S, v9.4S}, [x23], 12
    __ ld3r(v15, v16, v17, __ T1D, Address(__ post(r10, r6))); //       ld3r    {v15.1D, v16.1D, v17.1D}, [x10], x6
    __ ld4(v20, v21, v22, v23, __ T8H, Address(__ post(r25, 64))); //   ld4     {v20.8H, v21.8H, v22.8H, v23.8H}, [x25], 64
    __ ld4(v5, v6, v7, v8, __ T8B, Address(__ post(r27, r24))); //      ld4     {v5.8B, v6.8B, v7.8B, v8.8B}, [x27], x24
    __ ld4r(v5, v6, v7, v8, __ T8B, Address(r21));     //       ld4r    {v5.8B, v6.8B, v7.8B, v8.8B}, [x21]
    __ ld4r(v19, v20, v21, v22, __ T4H, Address(__ post(r27, 8))); //   ld4r    {v19.4H, v20.4H, v21.4H, v22.4H}, [x27], 8
    __ ld4r(v6, v7, v8, v9, __ T2S, Address(__ post(r30, r22))); //     ld4r    {v6.2S, v7.2S, v8.2S, v9.2S}, [x30], x22

// SHA512SIMDOp
    __ sha512h(v4, __ T2D, v23, v1);                   //       sha512h         q4, q23, v1.2D
    __ sha512h2(v3, __ T2D, v12, v13);                 //       sha512h2                q3, q12, v13.2D
    __ sha512su0(v27, __ T2D, v6);                     //       sha512su0               v27.2D, v6.2D
    __ sha512su1(v9, __ T2D, v21, v10);                //       sha512su1               v9.2D, v21.2D, v10.2D

// SpecialCases
    __ ccmn(zr, zr, 3u, Assembler::LE);                //       ccmn    xzr, xzr, #3, LE
    __ ccmnw(zr, zr, 5u, Assembler::EQ);               //       ccmn    wzr, wzr, #5, EQ
    __ ccmp(zr, 1, 4u, Assembler::NE);                 //       ccmp    xzr, 1, #4, NE
    __ ccmpw(zr, 2, 2, Assembler::GT);                 //       ccmp    wzr, 2, #2, GT
    __ extr(zr, zr, zr, 0);                            //       extr    xzr, xzr, xzr, 0
    __ stlxp(r0, zr, zr, sp);                          //       stlxp   w0, xzr, xzr, [sp]
    __ stlxpw(r2, zr, zr, r3);                         //       stlxp   w2, wzr, wzr, [x3]
    __ stxp(r4, zr, zr, r5);                           //       stxp    w4, xzr, xzr, [x5]
    __ stxpw(r6, zr, zr, sp);                          //       stxp    w6, wzr, wzr, [sp]
    __ dup(v0, __ T16B, zr);                           //       dup     v0.16b, wzr
    __ mov(v1, __ T1D, 0, zr);                         //       mov     v1.d[0], xzr
    __ mov(v1, __ T2S, 1, zr);                         //       mov     v1.s[1], wzr
    __ mov(v1, __ T4H, 2, zr);                         //       mov     v1.h[2], wzr
    __ mov(v1, __ T8B, 3, zr);                         //       mov     v1.b[3], wzr
    __ ld1(v31, v0, __ T2D, Address(__ post(r1, r0))); //       ld1     {v31.2d, v0.2d}, [x1], x0

// FloatImmediateOp
    __ fmovd(v0, 2.0);                                 //       fmov d0, #2.0
    __ fmovd(v0, 2.125);                               //       fmov d0, #2.125
    __ fmovd(v0, 4.0);                                 //       fmov d0, #4.0
    __ fmovd(v0, 4.25);                                //       fmov d0, #4.25
    __ fmovd(v0, 8.0);                                 //       fmov d0, #8.0
    __ fmovd(v0, 8.5);                                 //       fmov d0, #8.5
    __ fmovd(v0, 16.0);                                //       fmov d0, #16.0
    __ fmovd(v0, 17.0);                                //       fmov d0, #17.0
    __ fmovd(v0, 0.125);                               //       fmov d0, #0.125
    __ fmovd(v0, 0.1328125);                           //       fmov d0, #0.1328125
    __ fmovd(v0, 0.25);                                //       fmov d0, #0.25
    __ fmovd(v0, 0.265625);                            //       fmov d0, #0.265625
    __ fmovd(v0, 0.5);                                 //       fmov d0, #0.5
    __ fmovd(v0, 0.53125);                             //       fmov d0, #0.53125
    __ fmovd(v0, 1.0);                                 //       fmov d0, #1.0
    __ fmovd(v0, 1.0625);                              //       fmov d0, #1.0625
    __ fmovd(v0, -2.0);                                //       fmov d0, #-2.0
    __ fmovd(v0, -2.125);                              //       fmov d0, #-2.125
    __ fmovd(v0, -4.0);                                //       fmov d0, #-4.0
    __ fmovd(v0, -4.25);                               //       fmov d0, #-4.25
    __ fmovd(v0, -8.0);                                //       fmov d0, #-8.0
    __ fmovd(v0, -8.5);                                //       fmov d0, #-8.5
    __ fmovd(v0, -16.0);                               //       fmov d0, #-16.0
    __ fmovd(v0, -17.0);                               //       fmov d0, #-17.0
    __ fmovd(v0, -0.125);                              //       fmov d0, #-0.125
    __ fmovd(v0, -0.1328125);                          //       fmov d0, #-0.1328125
    __ fmovd(v0, -0.25);                               //       fmov d0, #-0.25
    __ fmovd(v0, -0.265625);                           //       fmov d0, #-0.265625
    __ fmovd(v0, -0.5);                                //       fmov d0, #-0.5
    __ fmovd(v0, -0.53125);                            //       fmov d0, #-0.53125
    __ fmovd(v0, -1.0);                                //       fmov d0, #-1.0
    __ fmovd(v0, -1.0625);                             //       fmov d0, #-1.0625

// LSEOp
    __ swp(Assembler::xword, r24, zr, r3);             //       swp     x24, xzr, [x3]
    __ ldadd(Assembler::xword, r5, r6, r5);            //       ldadd   x5, x6, [x5]
    __ ldbic(Assembler::xword, r25, r9, r12);          //       ldclr   x25, x9, [x12]
    __ ldeor(Assembler::xword, r9, r22, r9);           //       ldeor   x9, x22, [x9]
    __ ldorr(Assembler::xword, r14, r4, r1);           //       ldset   x14, x4, [x1]
    __ ldsmin(Assembler::xword, r23, r30, r29);        //       ldsmin  x23, x30, [x29]
    __ ldsmax(Assembler::xword, r21, r13, r26);        //       ldsmax  x21, x13, [x26]
    __ ldumin(Assembler::xword, r16, r9, r11);         //       ldumin  x16, x9, [x11]
    __ ldumax(Assembler::xword, r21, r17, r21);        //       ldumax  x21, x17, [x21]

// LSEOp
    __ swpa(Assembler::xword, r25, r25, r9);           //       swpa    x25, x25, [x9]
    __ ldadda(Assembler::xword, r5, r25, r6);          //       ldadda  x5, x25, [x6]
    __ ldbica(Assembler::xword, r24, r14, r23);        //       ldclra  x24, x14, [x23]
    __ ldeora(Assembler::xword, r19, r24, r26);        //       ldeora  x19, x24, [x26]
    __ ldorra(Assembler::xword, r15, r23, r2);         //       ldseta  x15, x23, [x2]
    __ ldsmina(Assembler::xword, r6, r7, r7);          //       ldsmina x6, x7, [x7]
    __ ldsmaxa(Assembler::xword, r30, r15, r14);       //       ldsmaxa x30, x15, [x14]
    __ ldumina(Assembler::xword, zr, r7, r5);          //       ldumina xzr, x7, [x5]
    __ ldumaxa(Assembler::xword, r20, r25, r1);        //       ldumaxa x20, x25, [x1]

// LSEOp
    __ swpal(Assembler::xword, r16, r18, r17);         //       swpal   x16, x18, [x17]
    __ ldaddal(Assembler::xword, r0, r15, r11);        //       ldaddal x0, x15, [x11]
    __ ldbical(Assembler::xword, r9, r17, r7);         //       ldclral x9, x17, [x7]
    __ ldeoral(Assembler::xword, r1, r23, r23);        //       ldeoral x1, x23, [x23]
    __ ldorral(Assembler::xword, r18, r1, r3);         //       ldsetal x18, x1, [x3]
    __ ldsminal(Assembler::xword, r27, zr, r8);        //       ldsminal        x27, xzr, [x8]
    __ ldsmaxal(Assembler::xword, r9, r27, r11);       //       ldsmaxal        x9, x27, [x11]
    __ lduminal(Assembler::xword, r25, r3, r3);        //       lduminal        x25, x3, [x3]
    __ ldumaxal(Assembler::xword, r16, r24, r25);      //       ldumaxal        x16, x24, [x25]

// LSEOp
    __ swpl(Assembler::xword, r6, r2, r29);            //       swpl    x6, x2, [x29]
    __ ldaddl(Assembler::xword, r23, r25, r12);        //       ldaddl  x23, x25, [x12]
    __ ldbicl(Assembler::xword, r9, r29, r23);         //       ldclrl  x9, x29, [x23]
    __ ldeorl(Assembler::xword, r29, r0, r2);          //       ldeorl  x29, x0, [x2]
    __ ldorrl(Assembler::xword, r19, r6, r10);         //       ldsetl  x19, x6, [x10]
    __ ldsminl(Assembler::xword, r17, r13, r25);       //       ldsminl x17, x13, [x25]
    __ ldsmaxl(Assembler::xword, r1, r23, r25);        //       ldsmaxl x1, x23, [x25]
    __ lduminl(Assembler::xword, r20, r26, r6);        //       lduminl x20, x26, [x6]
    __ ldumaxl(Assembler::xword, r13, r22, r12);       //       ldumaxl x13, x22, [x12]

// LSEOp
    __ swp(Assembler::word, r23, r24, r27);            //       swp     w23, w24, [x27]
    __ ldadd(Assembler::word, r3, r7, r20);            //       ldadd   w3, w7, [x20]
    __ ldbic(Assembler::word, r10, r21, r23);          //       ldclr   w10, w21, [x23]
    __ ldeor(Assembler::word, r9, r26, r12);           //       ldeor   w9, w26, [x12]
    __ ldorr(Assembler::word, r26, r23, r27);          //       ldset   w26, w23, [x27]
    __ ldsmin(Assembler::word, r4, r14, r21);          //       ldsmin  w4, w14, [x21]
    __ ldsmax(Assembler::word, r10, r0, r9);           //       ldsmax  w10, w0, [x9]
    __ ldumin(Assembler::word, r9, r13, r6);           //       ldumin  w9, w13, [x6]
    __ ldumax(Assembler::word, r9, zr, r21);           //       ldumax  w9, wzr, [x21]

// LSEOp
    __ swpa(Assembler::word, r12, r28, r11);           //       swpa    w12, w28, [x11]
    __ ldadda(Assembler::word, r8, r0, r12);           //       ldadda  w8, w0, [x12]
    __ ldbica(Assembler::word, r29, r7, r1);           //       ldclra  w29, w7, [x1]
    __ ldeora(Assembler::word, r29, r27, r25);         //       ldeora  w29, w27, [x25]
    __ ldorra(Assembler::word, r27, r16, r8);          //       ldseta  w27, w16, [x8]
    __ ldsmina(Assembler::word, r13, r18, sp);         //       ldsmina w13, w18, [sp]
    __ ldsmaxa(Assembler::word, r28, r0, r24);         //       ldsmaxa w28, w0, [x24]
    __ ldumina(Assembler::word, r28, r28, r13);        //       ldumina w28, w28, [x13]
    __ ldumaxa(Assembler::word, r14, r29, r2);         //       ldumaxa w14, w29, [x2]

// LSEOp
    __ swpal(Assembler::word, r8, r28, r17);           //       swpal   w8, w28, [x17]
    __ ldaddal(Assembler::word, r4, r10, r2);          //       ldaddal w4, w10, [x2]
    __ ldbical(Assembler::word, r0, r28, r14);         //       ldclral w0, w28, [x14]
    __ ldeoral(Assembler::word, r8, r12, r4);          //       ldeoral w8, w12, [x4]
    __ ldorral(Assembler::word, r1, r22, r13);         //       ldsetal w1, w22, [x13]
    __ ldsminal(Assembler::word, r24, r6, r20);        //       ldsminal        w24, w6, [x20]
    __ ldsmaxal(Assembler::word, r14, r14, r4);        //       ldsmaxal        w14, w14, [x4]
    __ lduminal(Assembler::word, r30, r2, r14);        //       lduminal        w30, w2, [x14]
    __ ldumaxal(Assembler::word, r2, r18, r22);        //       ldumaxal        w2, w18, [x22]

// LSEOp
    __ swpl(Assembler::word, r25, r25, r17);           //       swpl    w25, w25, [x17]
    __ ldaddl(Assembler::word, r4, r19, r7);           //       ldaddl  w4, w19, [x7]
    __ ldbicl(Assembler::word, r19, r15, r11);         //       ldclrl  w19, w15, [x11]
    __ ldeorl(Assembler::word, r23, r29, r16);         //       ldeorl  w23, w29, [x16]
    __ ldorrl(Assembler::word, r27, r5, r26);          //       ldsetl  w27, w5, [x26]
    __ ldsminl(Assembler::word, zr, r27, r0);          //       ldsminl wzr, w27, [x0]
    __ ldsmaxl(Assembler::word, r22, r6, r4);          //       ldsmaxl w22, w6, [x4]
    __ lduminl(Assembler::word, r13, r30, r2);         //       lduminl w13, w30, [x2]
    __ ldumaxl(Assembler::word, r19, r26, r12);        //       ldumaxl w19, w26, [x12]

    __ bind(forth);

/*
aarch64ops.o:     file format elf64-littleaarch64


Disassembly of section .text:

0000000000000000 <back>:
   0:   8b402464        add     x4, x3, x0, lsr #9
   4:   cb0447a8        sub     x8, x29, x4, lsl #17
   8:   ab174767        adds    x7, x27, x23, lsl #17
   c:   eb49a5e6        subs    x6, x15, x9, lsr #41
  10:   0b905c6c        add     w12, w3, w16, asr #23
  14:   4b5d7f08        sub     w8, w24, w29, lsr #31
  18:   2b0f1f87        adds    w7, w28, w15, lsl #7
  1c:   6b5c35fa        subs    w26, w15, w28, lsr #13
  20:   8a827101        and     x1, x8, x2, asr #28
  24:   aa4c2b73        orr     x19, x27, x12, lsr #10
  28:   ca4aed64        eor     x4, x11, x10, lsr #59
  2c:   ea027225        ands    x5, x17, x2, lsl #28
  30:   0a4c35fc        and     w28, w15, w12, lsr #13
  34:   2a5942ae        orr     w14, w21, w25, lsr #16
  38:   4a40120d        eor     w13, w16, w0, lsr #4
  3c:   6a504f5e        ands    w30, w26, w16, lsr #19
  40:   8a7956ec        bic     x12, x23, x25, lsr #21
  44:   aa6120ab        orn     x11, x5, x1, lsr #8
  48:   caa5da26        eon     x6, x17, x5, asr #54
  4c:   eaafca7e        bics    x30, x19, x15, asr #50
  50:   0a7b18cf        bic     w15, w6, w27, lsr #6
  54:   2aa61076        orn     w22, w3, w6, asr #4
  58:   4ab71482        eon     w2, w4, w23, asr #5
  5c:   6abe4ca2        bics    w2, w5, w30, asr #19
  60:   110e120c        add     w12, w16, #0x384
  64:   310aa10b        adds    w11, w8, #0x2a8
  68:   5100b0e8        sub     w8, w7, #0x2c
  6c:   710f89e8        subs    w8, w15, #0x3e2
  70:   91002740        add     x0, x26, #0x9
  74:   b10e865b        adds    x27, x18, #0x3a1
  78:   d104b112        sub     x18, x8, #0x12c
  7c:   f1091db4        subs    x20, x13, #0x247
  80:   121d4e7d        and     w29, w19, #0x7ffff8
  84:   3215606e        orr     w14, w3, #0xfffff80f
  88:   520c03ae        eor     w14, w29, #0x100000
  8c:   72174638        ands    w24, w17, #0x7fffe00
  90:   92022071        and     x17, x3, #0xc000007fc000007f
  94:   b2061dc7        orr     x7, x14, #0xfc000003fc000003
  98:   d245bb45        eor     x5, x26, #0xf80003ffffffffff
  9c:   f20a22ba        ands    x26, x21, #0x7fc000007fc00000
  a0:   14000000        b       a0 <back+0xa0>
  a4:   17ffffd7        b       0 <back>
  a8:   140001f2        b       870 <forth>
  ac:   94000000        bl      ac <back+0xac>
  b0:   97ffffd4        bl      0 <back>
  b4:   940001ef        bl      870 <forth>
  b8:   34000000        cbz     w0, b8 <back+0xb8>
  bc:   34fffa20        cbz     w0, 0 <back>
  c0:   34003d80        cbz     w0, 870 <forth>
  c4:   3500000b        cbnz    w11, c4 <back+0xc4>
  c8:   35fff9cb        cbnz    w11, 0 <back>
  cc:   35003d2b        cbnz    w11, 870 <forth>
  d0:   b4000015        cbz     x21, d0 <back+0xd0>
  d4:   b4fff975        cbz     x21, 0 <back>
  d8:   b4003cd5        cbz     x21, 870 <forth>
  dc:   b5000008        cbnz    x8, dc <back+0xdc>
  e0:   b5fff908        cbnz    x8, 0 <back>
  e4:   b5003c68        cbnz    x8, 870 <forth>
  e8:   1000000b        adr     x11, e8 <back+0xe8>
  ec:   10fff8ab        adr     x11, 0 <back>
  f0:   10003c0b        adr     x11, 870 <forth>
  f4:   90000000        adrp    x0, 0 <back>
  f8:   36100005        tbz     w5, #2, f8 <back+0xf8>
  fc:   3617f825        tbz     w5, #2, 0 <back>
 100:   36103b85        tbz     w5, #2, 870 <forth>
 104:   37200016        tbnz    w22, #4, 104 <back+0x104>
 108:   3727f7d6        tbnz    w22, #4, 0 <back>
 10c:   37203b36        tbnz    w22, #4, 870 <forth>
 110:   12a5b6d6        mov     w22, #0xd249ffff                // #-766902273
 114:   52ad7534        mov     w20, #0x6ba90000                // #1806237696
 118:   728edc9e        movk    w30, #0x76e4
 11c:   92ce63db        mov     x27, #0xffff8ce1ffffffff        // #-126572686213121
 120:   d2e3cc61        mov     x1, #0x1e63000000000000         // #2189593843832193024
 124:   f2a1d6a9        movk    x9, #0xeb5, lsl #16
 128:   9355739c        sbfx    x28, x28, #21, #8
 12c:   3308088f        bfi     w15, w4, #24, #3
 130:   53174135        ubfiz   w21, w9, #9, #17
 134:   935a576e        sbfiz   x14, x27, #38, #22
 138:   b35c74d3        bfxil   x19, x6, #28, #2
 13c:   d3500acb        ubfiz   x11, x22, #48, #3
 140:   138172c7        extr    w7, w22, w1, #28
 144:   93cedb75        extr    x21, x27, x14, #54
 148:   54000000        b.eq    148 <back+0x148>  // b.none
 14c:   54fff5a0        b.eq    0 <back>  // b.none
 150:   54003900        b.eq    870 <forth>  // b.none
 154:   54000001        b.ne    154 <back+0x154>  // b.any
 158:   54fff541        b.ne    0 <back>  // b.any
 15c:   540038a1        b.ne    870 <forth>  // b.any
 160:   54000002        b.cs    160 <back+0x160>  // b.hs, b.nlast
 164:   54fff4e2        b.cs    0 <back>  // b.hs, b.nlast
 168:   54003842        b.cs    870 <forth>  // b.hs, b.nlast
 16c:   54000002        b.cs    16c <back+0x16c>  // b.hs, b.nlast
 170:   54fff482        b.cs    0 <back>  // b.hs, b.nlast
 174:   540037e2        b.cs    870 <forth>  // b.hs, b.nlast
 178:   54000003        b.cc    178 <back+0x178>  // b.lo, b.ul, b.last
 17c:   54fff423        b.cc    0 <back>  // b.lo, b.ul, b.last
 180:   54003783        b.cc    870 <forth>  // b.lo, b.ul, b.last
 184:   54000003        b.cc    184 <back+0x184>  // b.lo, b.ul, b.last
 188:   54fff3c3        b.cc    0 <back>  // b.lo, b.ul, b.last
 18c:   54003723        b.cc    870 <forth>  // b.lo, b.ul, b.last
 190:   54000004        b.mi    190 <back+0x190>  // b.first
 194:   54fff364        b.mi    0 <back>  // b.first
 198:   540036c4        b.mi    870 <forth>  // b.first
 19c:   54000005        b.pl    19c <back+0x19c>  // b.nfrst
 1a0:   54fff305        b.pl    0 <back>  // b.nfrst
 1a4:   54003665        b.pl    870 <forth>  // b.nfrst
 1a8:   54000006        b.vs    1a8 <back+0x1a8>
 1ac:   54fff2a6        b.vs    0 <back>
 1b0:   54003606        b.vs    870 <forth>
 1b4:   54000007        b.vc    1b4 <back+0x1b4>
 1b8:   54fff247        b.vc    0 <back>
 1bc:   540035a7        b.vc    870 <forth>
 1c0:   54000008        b.hi    1c0 <back+0x1c0>  // b.pmore
 1c4:   54fff1e8        b.hi    0 <back>  // b.pmore
 1c8:   54003548        b.hi    870 <forth>  // b.pmore
 1cc:   54000009        b.ls    1cc <back+0x1cc>  // b.plast
 1d0:   54fff189        b.ls    0 <back>  // b.plast
 1d4:   540034e9        b.ls    870 <forth>  // b.plast
 1d8:   5400000a        b.ge    1d8 <back+0x1d8>  // b.tcont
 1dc:   54fff12a        b.ge    0 <back>  // b.tcont
 1e0:   5400348a        b.ge    870 <forth>  // b.tcont
 1e4:   5400000b        b.lt    1e4 <back+0x1e4>  // b.tstop
 1e8:   54fff0cb        b.lt    0 <back>  // b.tstop
 1ec:   5400342b        b.lt    870 <forth>  // b.tstop
 1f0:   5400000c        b.gt    1f0 <back+0x1f0>
 1f4:   54fff06c        b.gt    0 <back>
 1f8:   540033cc        b.gt    870 <forth>
 1fc:   5400000d        b.le    1fc <back+0x1fc>
 200:   54fff00d        b.le    0 <back>
 204:   5400336d        b.le    870 <forth>
 208:   5400000e        b.al    208 <back+0x208>
 20c:   54ffefae        b.al    0 <back>
 210:   5400330e        b.al    870 <forth>
 214:   5400000f        b.nv    214 <back+0x214>
 218:   54ffef4f        b.nv    0 <back>
 21c:   540032af        b.nv    870 <forth>
 220:   d40faaa1        svc     #0x7d55
 224:   d4025942        hvc     #0x12ca
 228:   d40ab883        smc     #0x55c4
 22c:   d42a4f00        brk     #0x5278
 230:   d447c560        hlt     #0x3e2b
 234:   d503201f        nop
 238:   d69f03e0        eret
 23c:   d6bf03e0        drps
 240:   d5033fdf        isb
 244:   d5033a9f        dsb     ishst
 248:   d5033abf        dmb     ishst
 24c:   d61f0220        br      x17
 250:   d63f0000        blr     x0
 254:   c8037d87        stxr    w3, x7, [x12]
 258:   c810fe4d        stlxr   w16, x13, [x18]
 25c:   c85f7fcb        ldxr    x11, [x30]
 260:   c85ffc75        ldaxr   x21, [x3]
 264:   c89fff56        stlr    x22, [x26]
 268:   c8dfff62        ldar    x2, [x27]
 26c:   88147c4f        stxr    w20, w15, [x2]
 270:   880bfda8        stlxr   w11, w8, [x13]
 274:   885f7f50        ldxr    w16, [x26]
 278:   885ffd7b        ldaxr   w27, [x11]
 27c:   889ffc9e        stlr    w30, [x4]
 280:   88dffd62        ldar    w2, [x11]
 284:   48167e5b        stxrh   w22, w27, [x18]
 288:   4819feea        stlxrh  w25, w10, [x23]
 28c:   485f7fcd        ldxrh   w13, [x30]
 290:   485ffc4d        ldaxrh  w13, [x2]
 294:   489fff02        stlrh   w2, [x24]
 298:   48dffef9        ldarh   w25, [x23]
 29c:   080d7fa0        stxrb   w13, w0, [x29]
 2a0:   0808fcd4        stlxrb  w8, w20, [x6]
 2a4:   085f7caf        ldxrb   w15, [x5]
 2a8:   085ffd40        ldaxrb  w0, [x10]
 2ac:   089fff4c        stlrb   w12, [x26]
 2b0:   08dffc4b        ldarb   w11, [x2]
 2b4:   c87f4537        ldxp    x23, x17, [x9]
 2b8:   c87f9da1        ldaxp   x1, x7, [x13]
 2bc:   c8272fa0        stxp    w7, x0, x11, [x29]
 2c0:   c8399576        stlxp   w25, x22, x5, [x11]
 2c4:   887f1b67        ldxp    w7, w6, [x27]
 2c8:   887f8b07        ldaxp   w7, w2, [x24]
 2cc:   88267a65        stxp    w6, w5, w30, [x19]
 2d0:   88229e5d        stlxp   w2, w29, w7, [x18]
 2d4:   f814929d        stur    x29, [x20, #-183]
 2d8:   b81d91a6        stur    w6, [x13, #-39]
 2dc:   381f50a9        sturb   w9, [x5, #-11]
 2e0:   78015116        sturh   w22, [x8, #21]
 2e4:   f85af3a1        ldur    x1, [x29, #-81]
 2e8:   b85e53b4        ldur    w20, [x29, #-27]
 2ec:   385f818f        ldurb   w15, [x12, #-8]
 2f0:   785c20e9        ldurh   w9, [x7, #-62]
 2f4:   389f71b7        ldursb  x23, [x13, #-9]
 2f8:   79803db2        ldrsh   x18, [x13, #30]
 2fc:   79c037d1        ldrsh   w17, [x30, #26]
 300:   b89831d5        ldursw  x21, [x14, #-125]
 304:   fc43b1b5        ldur    d21, [x13, #59]
 308:   bc43f115        ldur    s21, [x8, #63]
 30c:   fc035316        stur    d22, [x24, #53]
 310:   bc01501a        stur    s26, [x0, #21]
 314:   f8129ed7        str     x23, [x22, #-215]!
 318:   b81fdfbe        str     w30, [x29, #-3]!
 31c:   381eece2        strb    w2, [x7, #-18]!
 320:   78013d97        strh    w23, [x12, #19]!
 324:   f852ec92        ldr     x18, [x4, #-210]!
 328:   b85b9fd3        ldr     w19, [x30, #-71]!
 32c:   385f5e91        ldrb    w17, [x20, #-11]!
 330:   785c0dc9        ldrh    w9, [x14, #-64]!
 334:   3880bc66        ldrsb   x6, [x3, #11]!
 338:   789faecb        ldrsh   x11, [x22, #-6]!
 33c:   78de5d66        ldrsh   w6, [x11, #-27]!
 340:   b8836e59        ldrsw   x25, [x18, #54]!
 344:   fc5f8ef5        ldr     d21, [x23, #-8]!
 348:   bc5d9d5e        ldr     s30, [x10, #-39]!
 34c:   fc17fc22        str     d2, [x1, #-129]!
 350:   bc001c1a        str     s26, [x0, #1]!
 354:   f819d749        str     x9, [x26], #-99
 358:   b803e5c9        str     w9, [x14], #62
 35c:   381e275e        strb    w30, [x26], #-30
 360:   7800b61c        strh    w28, [x16], #11
 364:   f844d75d        ldr     x29, [x26], #77
 368:   b84356e0        ldr     w0, [x23], #53
 36c:   385ee6a7        ldrb    w7, [x21], #-18
 370:   784185b8        ldrh    w24, [x13], #24
 374:   389ef501        ldrsb   x1, [x8], #-17
 378:   789de771        ldrsh   x17, [x27], #-34
 37c:   78de6435        ldrsh   w21, [x1], #-26
 380:   b88006a6        ldrsw   x6, [x21], #0
 384:   fc43a465        ldr     d5, [x3], #58
 388:   bc5b0667        ldr     s7, [x19], #-80
 38c:   fc01b601        str     d1, [x16], #27
 390:   bc03e727        str     s7, [x25], #62
 394:   f83e586d        str     x13, [x3, w30, uxtw #3]
 398:   b821e871        str     w17, [x3, x1, sxtx]
 39c:   383b7a77        strb    w23, [x19, x27, lsl #0]
 3a0:   782a5a85        strh    w5, [x20, w10, uxtw #1]
 3a4:   f870d85d        ldr     x29, [x2, w16, sxtw #3]
 3a8:   b875fa30        ldr     w16, [x17, x21, sxtx #2]
 3ac:   38705a0a        ldrb    w10, [x16, w16, uxtw #0]
 3b0:   787adb77        ldrh    w23, [x27, w26, sxtw #1]
 3b4:   38a7780d        ldrsb   x13, [x0, x7, lsl #0]
 3b8:   78b248af        ldrsh   x15, [x5, w18, uxtw]
 3bc:   78f27a92        ldrsh   w18, [x20, x18, lsl #1]
 3c0:   b8b149de        ldrsw   x30, [x14, w17, uxtw]
 3c4:   fc7a58d3        ldr     d19, [x6, w26, uxtw #3]
 3c8:   bc62cafe        ldr     s30, [x23, w2, sxtw]
 3cc:   fc274adb        str     d27, [x22, w7, uxtw]
 3d0:   bc3afb09        str     s9, [x24, x26, sxtx #2]
 3d4:   f91f778e        str     x14, [x28, #16104]
 3d8:   b91eb9b0        str     w16, [x13, #7864]
 3dc:   39186b74        strb    w20, [x27, #1562]
 3e0:   791988f0        strh    w16, [x7, #3268]
 3e4:   f95e4ea5        ldr     x5, [x21, #15512]
 3e8:   b95de900        ldr     w0, [x8, #7656]
 3ec:   395f90e1        ldrb    w1, [x7, #2020]
 3f0:   7959bdc1        ldrh    w1, [x14, #3294]
 3f4:   399b9b26        ldrsb   x6, [x25, #1766]
 3f8:   79996209        ldrsh   x9, [x16, #3248]
 3fc:   79dc309b        ldrsh   w27, [x4, #3608]
 400:   b99c8e02        ldrsw   x2, [x16, #7308]
 404:   fd5fa345        ldr     d5, [x26, #16192]
 408:   bd5efdb3        ldr     s19, [x13, #7932]
 40c:   fd1a20f6        str     d22, [x7, #13376]
 410:   bd1e8928        str     s8, [x9, #7816]
 414:   58ffdf7a        ldr     x26, 0 <back>
 418:   18ffdf4c        ldr     w12, 0 <back>
 41c:   f882f140        prfum   pldl1keep, [x10, #47]
 420:   d8002280        prfm    pldl1keep, 870 <forth>
 424:   f8b47aa0        prfm    pldl1keep, [x21, x20, lsl #3]
 428:   f99ed1a0        prfm    pldl1keep, [x13, #15776]
 42c:   1a03011a        adc     w26, w8, w3
 430:   3a0703c9        adcs    w9, w30, w7
 434:   5a0b01f8        sbc     w24, w15, w11
 438:   7a0b02a4        sbcs    w4, w21, w11
 43c:   9a1e022f        adc     x15, x17, x30
 440:   ba1001e6        adcs    x6, x15, x16
 444:   da0a0041        sbc     x1, x2, x10
 448:   fa0b0089        sbcs    x9, x4, x11
 44c:   0b3167b7        add     w23, w29, w17, uxtx #1
 450:   2b2bed6f        adds    w15, w11, w11, sxtx #3
 454:   cb2753c2        sub     x2, x30, w7, uxtw #4
 458:   6b3a867e        subs    w30, w19, w26, sxtb #1
 45c:   8b2c6c02        add     x2, x0, x12, uxtx #3
 460:   ab30902e        adds    x14, x1, w16, sxtb #4
 464:   cb378ecf        sub     x15, x22, w23, sxtb #3
 468:   eb3c4480        subs    x0, x4, w28, uxtw #1
 46c:   3a5220ab        ccmn    w5, w18, #0xb, cs  // cs = hs, nlast
 470:   7a552248        ccmp    w18, w21, #0x8, cs  // cs = hs, nlast
 474:   ba5131ef        ccmn    x15, x17, #0xf, cc  // cc = lo, ul, last
 478:   fa5711a6        ccmp    x13, x23, #0x6, ne  // ne = any
 47c:   3a493b8f        ccmn    w28, #0x9, #0xf, cc  // cc = lo, ul, last
 480:   7a4c99c9        ccmp    w14, #0xc, #0x9, ls  // ls = plast
 484:   ba463ac2        ccmn    x22, #0x6, #0x2, cc  // cc = lo, ul, last
 488:   fa4c4aa0        ccmp    x21, #0xc, #0x0, mi  // mi = first
 48c:   1a9cc2ae        csel    w14, w21, w28, gt
 490:   1a91c5d9        csinc   w25, w14, w17, gt
 494:   5a9920d1        csinv   w17, w6, w25, cs  // cs = hs, nlast
 498:   5a8e2455        csneg   w21, w2, w14, cs  // cs = hs, nlast
 49c:   9a912163        csel    x3, x11, x17, cs  // cs = hs, nlast
 4a0:   9a9b27db        csinc   x27, x30, x27, cs  // cs = hs, nlast
 4a4:   da8581e0        csinv   x0, x15, x5, hi  // hi = pmore
 4a8:   da882562        csneg   x2, x11, x8, cs  // cs = hs, nlast
 4ac:   5ac00262        rbit    w2, w19
 4b0:   5ac00596        rev16   w22, w12
 4b4:   5ac00ac5        rev     w5, w22
 4b8:   5ac01363        clz     w3, w27
 4bc:   5ac01492        cls     w18, w4
 4c0:   dac00376        rbit    x22, x27
 4c4:   dac0054c        rev16   x12, x10
 4c8:   dac00885        rev32   x5, x4
 4cc:   dac00d56        rev     x22, x10
 4d0:   dac010ed        clz     x13, x7
 4d4:   dac01546        cls     x6, x10
 4d8:   1adc0a02        udiv    w2, w16, w28
 4dc:   1ac80ee8        sdiv    w8, w23, w8
 4e0:   1ace2232        lsl     w18, w17, w14
 4e4:   1ad6273e        lsr     w30, w25, w22
 4e8:   1ac52850        asr     w16, w2, w5
 4ec:   1ac02f8f        ror     w15, w28, w0
 4f0:   9ac10a8d        udiv    x13, x20, x1
 4f4:   9ad20fdc        sdiv    x28, x30, x18
 4f8:   9ac92391        lsl     x17, x28, x9
 4fc:   9ac425b2        lsr     x18, x13, x4
 500:   9ad02b0c        asr     x12, x24, x16
 504:   9ad82d2e        ror     x14, x9, x24
 508:   9bd87c94        umulh   x20, x4, x24
 50c:   9b5c7cb2        smulh   x18, x5, x28
 510:   1b114bb3        madd    w19, w29, w17, w18
 514:   1b0fcece        msub    w14, w22, w15, w19
 518:   9b0120ac        madd    x12, x5, x1, x8
 51c:   9b0bc256        msub    x22, x18, x11, x16
 520:   9b2c7960        smaddl  x0, w11, w12, x30
 524:   9b2db113        smsubl  x19, w8, w13, x12
 528:   9bb117cd        umaddl  x13, w30, w17, x5
 52c:   9bb7a590        umsubl  x16, w12, w23, x9
 530:   1e200a86        fmul    s6, s20, s0
 534:   1e2f18d5        fdiv    s21, s6, s15
 538:   1e392938        fadd    s24, s9, s25
 53c:   1e323b09        fsub    s9, s24, s18
 540:   1e2a0b1a        fmul    s26, s24, s10
 544:   1e600a8c        fmul    d12, d20, d0
 548:   1e7019ec        fdiv    d12, d15, d16
 54c:   1e7d28d8        fadd    d24, d6, d29
 550:   1e6e38d8        fsub    d24, d6, d14
 554:   1e6f0bb5        fmul    d21, d29, d15
 558:   1f017729        fmadd   s9, s25, s1, s29
 55c:   1f0af68d        fmsub   s13, s20, s10, s29
 560:   1f2b1d7c        fnmadd  s28, s11, s11, s7
 564:   1f350787        fnmadd  s7, s28, s21, s1
 568:   1f4f07be        fmadd   d30, d29, d15, d1
 56c:   1f5be90c        fmsub   d12, d8, d27, d26
 570:   1f6b6711        fnmadd  d17, d24, d11, d25
 574:   1f68003e        fnmadd  d30, d1, d8, d0
 578:   1e2040a1        fmov    s1, s5
 57c:   1e20c266        fabs    s6, s19
 580:   1e214004        fneg    s4, s0
 584:   1e21c149        fsqrt   s9, s10
 588:   1e22c1d4        fcvt    d20, s14
 58c:   1e604260        fmov    d0, d19
 590:   1e60c25e        fabs    d30, d18
 594:   1e614100        fneg    d0, d8
 598:   1e61c100        fsqrt   d0, d8
 59c:   1e6243ce        fcvt    s14, d30
 5a0:   1e3802d3        fcvtzs  w19, s22
 5a4:   9e380151        fcvtzs  x17, s10
 5a8:   1e7802bb        fcvtzs  w27, d21
 5ac:   9e780087        fcvtzs  x7, d4
 5b0:   1e22033e        scvtf   s30, w25
 5b4:   9e220219        scvtf   s25, x16
 5b8:   1e620349        scvtf   d9, w26
 5bc:   9e620007        scvtf   d7, x0
 5c0:   1e2601e0        fmov    w0, s15
 5c4:   9e66008b        fmov    x11, d4
 5c8:   1e2701fe        fmov    s30, w15
 5cc:   9e6702e2        fmov    d2, x23
 5d0:   1e2a21c0        fcmp    s14, s10
 5d4:   1e6023c0        fcmp    d30, d0
 5d8:   1e202168        fcmp    s11, #0.0
 5dc:   1e602308        fcmp    d24, #0.0
 5e0:   2922403c        stp     w28, w16, [x1, #-240]
 5e4:   294c55d7        ldp     w23, w21, [x14, #96]
 5e8:   697860e0        ldpsw   x0, x24, [x7, #-64]
 5ec:   a9085215        stp     x21, x20, [x16, #128]
 5f0:   a9790f41        ldp     x1, x3, [x26, #-112]
 5f4:   29a2394c        stp     w12, w14, [x10, #-240]!
 5f8:   29e200e3        ldp     w3, w0, [x7, #-240]!
 5fc:   69e660ba        ldpsw   x26, x24, [x5, #-208]!
 600:   a9b65910        stp     x16, x22, [x8, #-160]!
 604:   a9f711fa        ldp     x26, x4, [x15, #-144]!
 608:   288e73a9        stp     w9, w28, [x29], #112
 60c:   28c81468        ldp     w8, w5, [x3], #64
 610:   68e6119e        ldpsw   x30, x4, [x12], #-208
 614:   a8b67a0e        stp     x14, x30, [x16], #-160
 618:   a8f3593b        ldp     x27, x22, [x9], #-208
 61c:   2820571a        stnp    w26, w21, [x24, #-256]
 620:   287a25f4        ldnp    w20, w9, [x15, #-48]
 624:   a83169af        stnp    x15, x26, [x13, #-240]
 628:   a84168a5        ldnp    x5, x26, [x5, #16]
 62c:   0c407353        ld1     {v19.8b}, [x26]
 630:   4cdfa1c1        ld1     {v1.16b, v2.16b}, [x14], #32
 634:   0cd96f1d        ld1     {v29.1d-v31.1d}, [x24], x25
 638:   4cdf2414        ld1     {v20.8h-v23.8h}, [x0], #64
 63c:   0d40c379        ld1r    {v25.8b}, [x27]
 640:   4ddfcb5e        ld1r    {v30.4s}, [x26], #4
 644:   0dcacea9        ld1r    {v9.1d}, [x21], x10
 648:   4c408dc2        ld2     {v2.2d, v3.2d}, [x14]
 64c:   0cdf864e        ld2     {v14.4h, v15.4h}, [x18], #16
 650:   4d60c004        ld2r    {v4.16b, v5.16b}, [x0]
 654:   0dffc832        ld2r    {v18.2s, v19.2s}, [x1], #8
 658:   4dfbcc1a        ld2r    {v26.2d, v27.2d}, [x0], x27
 65c:   4cc34ac7        ld3     {v7.4s-v9.4s}, [x22], x3
 660:   0c404aa5        ld3     {v5.2s-v7.2s}, [x21]
 664:   4d40e4fe        ld3r    {v30.8h, v31.8h, v0.8h}, [x7]
 668:   4ddfeae7        ld3r    {v7.4s-v9.4s}, [x23], #12
 66c:   0dc6ed4f        ld3r    {v15.1d-v17.1d}, [x10], x6
 670:   4cdf0734        ld4     {v20.8h-v23.8h}, [x25], #64
 674:   0cd80365        ld4     {v5.8b-v8.8b}, [x27], x24
 678:   0d60e2a5        ld4r    {v5.8b-v8.8b}, [x21]
 67c:   0dffe773        ld4r    {v19.4h-v22.4h}, [x27], #8
 680:   0df6ebc6        ld4r    {v6.2s-v9.2s}, [x30], x22
 684:   ce6182e4        sha512h q4, q23, v1.2d
 688:   ce6d8583        sha512h2        q3, q12, v13.2d
 68c:   cec080db        sha512su0       v27.2d, v6.2d
 690:   ce6a8aa9        sha512su1       v9.2d, v21.2d, v10.2d
 694:   ba5fd3e3        ccmn    xzr, xzr, #0x3, le
 698:   3a5f03e5        ccmn    wzr, wzr, #0x5, eq  // eq = none
 69c:   fa411be4        ccmp    xzr, #0x1, #0x4, ne  // ne = any
 6a0:   7a42cbe2        ccmp    wzr, #0x2, #0x2, gt
 6a4:   93df03ff        ror     xzr, xzr, #0
 6a8:   c820ffff        stlxp   w0, xzr, xzr, [sp]
 6ac:   8822fc7f        stlxp   w2, wzr, wzr, [x3]
 6b0:   c8247cbf        stxp    w4, xzr, xzr, [x5]
 6b4:   88267fff        stxp    w6, wzr, wzr, [sp]
 6b8:   4e010fe0        dup     v0.16b, wzr
 6bc:   4e081fe1        mov     v1.d[0], xzr
 6c0:   4e0c1fe1        mov     v1.s[1], wzr
 6c4:   4e0a1fe1        mov     v1.h[2], wzr
 6c8:   4e071fe1        mov     v1.b[3], wzr
 6cc:   4cc0ac3f        ld1     {v31.2d, v0.2d}, [x1], x0
 6d0:   1e601000        fmov    d0, #2.000000000000000000e+00
 6d4:   1e603000        fmov    d0, #2.125000000000000000e+00
 6d8:   1e621000        fmov    d0, #4.000000000000000000e+00
 6dc:   1e623000        fmov    d0, #4.250000000000000000e+00
 6e0:   1e641000        fmov    d0, #8.000000000000000000e+00
 6e4:   1e643000        fmov    d0, #8.500000000000000000e+00
 6e8:   1e661000        fmov    d0, #1.600000000000000000e+01
 6ec:   1e663000        fmov    d0, #1.700000000000000000e+01
 6f0:   1e681000        fmov    d0, #1.250000000000000000e-01
 6f4:   1e683000        fmov    d0, #1.328125000000000000e-01
 6f8:   1e6a1000        fmov    d0, #2.500000000000000000e-01
 6fc:   1e6a3000        fmov    d0, #2.656250000000000000e-01
 700:   1e6c1000        fmov    d0, #5.000000000000000000e-01
 704:   1e6c3000        fmov    d0, #5.312500000000000000e-01
 708:   1e6e1000        fmov    d0, #1.000000000000000000e+00
 70c:   1e6e3000        fmov    d0, #1.062500000000000000e+00
 710:   1e701000        fmov    d0, #-2.000000000000000000e+00
 714:   1e703000        fmov    d0, #-2.125000000000000000e+00
 718:   1e721000        fmov    d0, #-4.000000000000000000e+00
 71c:   1e723000        fmov    d0, #-4.250000000000000000e+00
 720:   1e741000        fmov    d0, #-8.000000000000000000e+00
 724:   1e743000        fmov    d0, #-8.500000000000000000e+00
 728:   1e761000        fmov    d0, #-1.600000000000000000e+01
 72c:   1e763000        fmov    d0, #-1.700000000000000000e+01
 730:   1e781000        fmov    d0, #-1.250000000000000000e-01
 734:   1e783000        fmov    d0, #-1.328125000000000000e-01
 738:   1e7a1000        fmov    d0, #-2.500000000000000000e-01
 73c:   1e7a3000        fmov    d0, #-2.656250000000000000e-01
 740:   1e7c1000        fmov    d0, #-5.000000000000000000e-01
 744:   1e7c3000        fmov    d0, #-5.312500000000000000e-01
 748:   1e7e1000        fmov    d0, #-1.000000000000000000e+00
 74c:   1e7e3000        fmov    d0, #-1.062500000000000000e+00
 750:   f838807f        swp     x24, xzr, [x3]
 754:   f82500a6        ldadd   x5, x6, [x5]
 758:   f8391189        ldclr   x25, x9, [x12]
 75c:   f8292136        ldeor   x9, x22, [x9]
 760:   f82e3024        ldset   x14, x4, [x1]
 764:   f83753be        ldsmin  x23, x30, [x29]
 768:   f835434d        ldsmax  x21, x13, [x26]
 76c:   f8307169        ldumin  x16, x9, [x11]
 770:   f83562b1        ldumax  x21, x17, [x21]
 774:   f8b98139        swpa    x25, x25, [x9]
 778:   f8a500d9        ldadda  x5, x25, [x6]
 77c:   f8b812ee        ldclra  x24, x14, [x23]
 780:   f8b32358        ldeora  x19, x24, [x26]
 784:   f8af3057        ldseta  x15, x23, [x2]
 788:   f8a650e7        ldsmina x6, x7, [x7]
 78c:   f8be41cf        ldsmaxa x30, x15, [x14]
 790:   f8bf70a7        ldumina xzr, x7, [x5]
 794:   f8b46039        ldumaxa x20, x25, [x1]
 798:   f8f08232        swpal   x16, x18, [x17]
 79c:   f8e0016f        ldaddal x0, x15, [x11]
 7a0:   f8e910f1        ldclral x9, x17, [x7]
 7a4:   f8e122f7        ldeoral x1, x23, [x23]
 7a8:   f8f23061        ldsetal x18, x1, [x3]
 7ac:   f8fb511f        ldsminal        x27, xzr, [x8]
 7b0:   f8e9417b        ldsmaxal        x9, x27, [x11]
 7b4:   f8f97063        lduminal        x25, x3, [x3]
 7b8:   f8f06338        ldumaxal        x16, x24, [x25]
 7bc:   f86683a2        swpl    x6, x2, [x29]
 7c0:   f8770199        ldaddl  x23, x25, [x12]
 7c4:   f86912fd        ldclrl  x9, x29, [x23]
 7c8:   f87d2040        ldeorl  x29, x0, [x2]
 7cc:   f8733146        ldsetl  x19, x6, [x10]
 7d0:   f871532d        ldsminl x17, x13, [x25]
 7d4:   f8614337        ldsmaxl x1, x23, [x25]
 7d8:   f87470da        lduminl x20, x26, [x6]
 7dc:   f86d6196        ldumaxl x13, x22, [x12]
 7e0:   b8378378        swp     w23, w24, [x27]
 7e4:   b8230287        ldadd   w3, w7, [x20]
 7e8:   b82a12f5        ldclr   w10, w21, [x23]
 7ec:   b829219a        ldeor   w9, w26, [x12]
 7f0:   b83a3377        ldset   w26, w23, [x27]
 7f4:   b82452ae        ldsmin  w4, w14, [x21]
 7f8:   b82a4120        ldsmax  w10, w0, [x9]
 7fc:   b82970cd        ldumin  w9, w13, [x6]
 800:   b82962bf        stumax  w9, [x21]
 804:   b8ac817c        swpa    w12, w28, [x11]
 808:   b8a80180        ldadda  w8, w0, [x12]
 80c:   b8bd1027        ldclra  w29, w7, [x1]
 810:   b8bd233b        ldeora  w29, w27, [x25]
 814:   b8bb3110        ldseta  w27, w16, [x8]
 818:   b8ad53f2        ldsmina w13, w18, [sp]
 81c:   b8bc4300        ldsmaxa w28, w0, [x24]
 820:   b8bc71bc        ldumina w28, w28, [x13]
 824:   b8ae605d        ldumaxa w14, w29, [x2]
 828:   b8e8823c        swpal   w8, w28, [x17]
 82c:   b8e4004a        ldaddal w4, w10, [x2]
 830:   b8e011dc        ldclral w0, w28, [x14]
 834:   b8e8208c        ldeoral w8, w12, [x4]
 838:   b8e131b6        ldsetal w1, w22, [x13]
 83c:   b8f85286        ldsminal        w24, w6, [x20]
 840:   b8ee408e        ldsmaxal        w14, w14, [x4]
 844:   b8fe71c2        lduminal        w30, w2, [x14]
 848:   b8e262d2        ldumaxal        w2, w18, [x22]
 84c:   b8798239        swpl    w25, w25, [x17]
 850:   b86400f3        ldaddl  w4, w19, [x7]
 854:   b873116f        ldclrl  w19, w15, [x11]
 858:   b877221d        ldeorl  w23, w29, [x16]
 85c:   b87b3345        ldsetl  w27, w5, [x26]
 860:   b87f501b        ldsminl wzr, w27, [x0]
 864:   b8764086        ldsmaxl w22, w6, [x4]
 868:   b86d705e        lduminl w13, w30, [x2]
 86c:   b873619a        ldumaxl w19, w26, [x12]
 */

  static const unsigned int insns[] =
  {
    0x8b402464,     0xcb0447a8,     0xab174767,     0xeb49a5e6,
    0x0b905c6c,     0x4b5d7f08,     0x2b0f1f87,     0x6b5c35fa,
    0x8a827101,     0xaa4c2b73,     0xca4aed64,     0xea027225,
    0x0a4c35fc,     0x2a5942ae,     0x4a40120d,     0x6a504f5e,
    0x8a7956ec,     0xaa6120ab,     0xcaa5da26,     0xeaafca7e,
    0x0a7b18cf,     0x2aa61076,     0x4ab71482,     0x6abe4ca2,
    0x110e120c,     0x310aa10b,     0x5100b0e8,     0x710f89e8,
    0x91002740,     0xb10e865b,     0xd104b112,     0xf1091db4,
    0x121d4e7d,     0x3215606e,     0x520c03ae,     0x72174638,
    0x92022071,     0xb2061dc7,     0xd245bb45,     0xf20a22ba,
    0x14000000,     0x17ffffd7,     0x140001f2,     0x94000000,
    0x97ffffd4,     0x940001ef,     0x34000000,     0x34fffa20,
    0x34003d80,     0x3500000b,     0x35fff9cb,     0x35003d2b,
    0xb4000015,     0xb4fff975,     0xb4003cd5,     0xb5000008,
    0xb5fff908,     0xb5003c68,     0x1000000b,     0x10fff8ab,
    0x10003c0b,     0x90000000,     0x36100005,     0x3617f825,
    0x36103b85,     0x37200016,     0x3727f7d6,     0x37203b36,
    0x12a5b6d6,     0x52ad7534,     0x728edc9e,     0x92ce63db,
    0xd2e3cc61,     0xf2a1d6a9,     0x9355739c,     0x3308088f,
    0x53174135,     0x935a576e,     0xb35c74d3,     0xd3500acb,
    0x138172c7,     0x93cedb75,     0x54000000,     0x54fff5a0,
    0x54003900,     0x54000001,     0x54fff541,     0x540038a1,
    0x54000002,     0x54fff4e2,     0x54003842,     0x54000002,
    0x54fff482,     0x540037e2,     0x54000003,     0x54fff423,
    0x54003783,     0x54000003,     0x54fff3c3,     0x54003723,
    0x54000004,     0x54fff364,     0x540036c4,     0x54000005,
    0x54fff305,     0x54003665,     0x54000006,     0x54fff2a6,
    0x54003606,     0x54000007,     0x54fff247,     0x540035a7,
    0x54000008,     0x54fff1e8,     0x54003548,     0x54000009,
    0x54fff189,     0x540034e9,     0x5400000a,     0x54fff12a,
    0x5400348a,     0x5400000b,     0x54fff0cb,     0x5400342b,
    0x5400000c,     0x54fff06c,     0x540033cc,     0x5400000d,
    0x54fff00d,     0x5400336d,     0x5400000e,     0x54ffefae,
    0x5400330e,     0x5400000f,     0x54ffef4f,     0x540032af,
    0xd40faaa1,     0xd4025942,     0xd40ab883,     0xd42a4f00,
    0xd447c560,     0xd503201f,     0xd69f03e0,     0xd6bf03e0,
    0xd5033fdf,     0xd5033a9f,     0xd5033abf,     0xd61f0220,
    0xd63f0000,     0xc8037d87,     0xc810fe4d,     0xc85f7fcb,
    0xc85ffc75,     0xc89fff56,     0xc8dfff62,     0x88147c4f,
    0x880bfda8,     0x885f7f50,     0x885ffd7b,     0x889ffc9e,
    0x88dffd62,     0x48167e5b,     0x4819feea,     0x485f7fcd,
    0x485ffc4d,     0x489fff02,     0x48dffef9,     0x080d7fa0,
    0x0808fcd4,     0x085f7caf,     0x085ffd40,     0x089fff4c,
    0x08dffc4b,     0xc87f4537,     0xc87f9da1,     0xc8272fa0,
    0xc8399576,     0x887f1b67,     0x887f8b07,     0x88267a65,
    0x88229e5d,     0xf814929d,     0xb81d91a6,     0x381f50a9,
    0x78015116,     0xf85af3a1,     0xb85e53b4,     0x385f818f,
    0x785c20e9,     0x389f71b7,     0x79803db2,     0x79c037d1,
    0xb89831d5,     0xfc43b1b5,     0xbc43f115,     0xfc035316,
    0xbc01501a,     0xf8129ed7,     0xb81fdfbe,     0x381eece2,
    0x78013d97,     0xf852ec92,     0xb85b9fd3,     0x385f5e91,
    0x785c0dc9,     0x3880bc66,     0x789faecb,     0x78de5d66,
    0xb8836e59,     0xfc5f8ef5,     0xbc5d9d5e,     0xfc17fc22,
    0xbc001c1a,     0xf819d749,     0xb803e5c9,     0x381e275e,
    0x7800b61c,     0xf844d75d,     0xb84356e0,     0x385ee6a7,
    0x784185b8,     0x389ef501,     0x789de771,     0x78de6435,
    0xb88006a6,     0xfc43a465,     0xbc5b0667,     0xfc01b601,
    0xbc03e727,     0xf83e586d,     0xb821e871,     0x383b7a77,
    0x782a5a85,     0xf870d85d,     0xb875fa30,     0x38705a0a,
    0x787adb77,     0x38a7780d,     0x78b248af,     0x78f27a92,
    0xb8b149de,     0xfc7a58d3,     0xbc62cafe,     0xfc274adb,
    0xbc3afb09,     0xf91f778e,     0xb91eb9b0,     0x39186b74,
    0x791988f0,     0xf95e4ea5,     0xb95de900,     0x395f90e1,
    0x7959bdc1,     0x399b9b26,     0x79996209,     0x79dc309b,
    0xb99c8e02,     0xfd5fa345,     0xbd5efdb3,     0xfd1a20f6,
    0xbd1e8928,     0x58ffdf7a,     0x18ffdf4c,     0xf882f140,
    0xd8002280,     0xf8b47aa0,     0xf99ed1a0,     0x1a03011a,
    0x3a0703c9,     0x5a0b01f8,     0x7a0b02a4,     0x9a1e022f,
    0xba1001e6,     0xda0a0041,     0xfa0b0089,     0x0b3167b7,
    0x2b2bed6f,     0xcb2753c2,     0x6b3a867e,     0x8b2c6c02,
    0xab30902e,     0xcb378ecf,     0xeb3c4480,     0x3a5220ab,
    0x7a552248,     0xba5131ef,     0xfa5711a6,     0x3a493b8f,
    0x7a4c99c9,     0xba463ac2,     0xfa4c4aa0,     0x1a9cc2ae,
    0x1a91c5d9,     0x5a9920d1,     0x5a8e2455,     0x9a912163,
    0x9a9b27db,     0xda8581e0,     0xda882562,     0x5ac00262,
    0x5ac00596,     0x5ac00ac5,     0x5ac01363,     0x5ac01492,
    0xdac00376,     0xdac0054c,     0xdac00885,     0xdac00d56,
    0xdac010ed,     0xdac01546,     0x1adc0a02,     0x1ac80ee8,
    0x1ace2232,     0x1ad6273e,     0x1ac52850,     0x1ac02f8f,
    0x9ac10a8d,     0x9ad20fdc,     0x9ac92391,     0x9ac425b2,
    0x9ad02b0c,     0x9ad82d2e,     0x9bd87c94,     0x9b5c7cb2,
    0x1b114bb3,     0x1b0fcece,     0x9b0120ac,     0x9b0bc256,
    0x9b2c7960,     0x9b2db113,     0x9bb117cd,     0x9bb7a590,
    0x1e200a86,     0x1e2f18d5,     0x1e392938,     0x1e323b09,
    0x1e2a0b1a,     0x1e600a8c,     0x1e7019ec,     0x1e7d28d8,
    0x1e6e38d8,     0x1e6f0bb5,     0x1f017729,     0x1f0af68d,
    0x1f2b1d7c,     0x1f350787,     0x1f4f07be,     0x1f5be90c,
    0x1f6b6711,     0x1f68003e,     0x1e2040a1,     0x1e20c266,
    0x1e214004,     0x1e21c149,     0x1e22c1d4,     0x1e604260,
    0x1e60c25e,     0x1e614100,     0x1e61c100,     0x1e6243ce,
    0x1e3802d3,     0x9e380151,     0x1e7802bb,     0x9e780087,
    0x1e22033e,     0x9e220219,     0x1e620349,     0x9e620007,
    0x1e2601e0,     0x9e66008b,     0x1e2701fe,     0x9e6702e2,
    0x1e2a21c0,     0x1e6023c0,     0x1e202168,     0x1e602308,
    0x2922403c,     0x294c55d7,     0x697860e0,     0xa9085215,
    0xa9790f41,     0x29a2394c,     0x29e200e3,     0x69e660ba,
    0xa9b65910,     0xa9f711fa,     0x288e73a9,     0x28c81468,
    0x68e6119e,     0xa8b67a0e,     0xa8f3593b,     0x2820571a,
    0x287a25f4,     0xa83169af,     0xa84168a5,     0x0c407353,
    0x4cdfa1c1,     0x0cd96f1d,     0x4cdf2414,     0x0d40c379,
    0x4ddfcb5e,     0x0dcacea9,     0x4c408dc2,     0x0cdf864e,
    0x4d60c004,     0x0dffc832,     0x4dfbcc1a,     0x4cc34ac7,
    0x0c404aa5,     0x4d40e4fe,     0x4ddfeae7,     0x0dc6ed4f,
    0x4cdf0734,     0x0cd80365,     0x0d60e2a5,     0x0dffe773,
    0x0df6ebc6,     0xce6182e4,     0xce6d8583,     0xcec080db,
    0xce6a8aa9,     0xba5fd3e3,     0x3a5f03e5,     0xfa411be4,
    0x7a42cbe2,     0x93df03ff,     0xc820ffff,     0x8822fc7f,
    0xc8247cbf,     0x88267fff,     0x4e010fe0,     0x4e081fe1,
    0x4e0c1fe1,     0x4e0a1fe1,     0x4e071fe1,     0x4cc0ac3f,
    0x1e601000,     0x1e603000,     0x1e621000,     0x1e623000,
    0x1e641000,     0x1e643000,     0x1e661000,     0x1e663000,
    0x1e681000,     0x1e683000,     0x1e6a1000,     0x1e6a3000,
    0x1e6c1000,     0x1e6c3000,     0x1e6e1000,     0x1e6e3000,
    0x1e701000,     0x1e703000,     0x1e721000,     0x1e723000,
    0x1e741000,     0x1e743000,     0x1e761000,     0x1e763000,
    0x1e781000,     0x1e783000,     0x1e7a1000,     0x1e7a3000,
    0x1e7c1000,     0x1e7c3000,     0x1e7e1000,     0x1e7e3000,
    0xf838807f,     0xf82500a6,     0xf8391189,     0xf8292136,
    0xf82e3024,     0xf83753be,     0xf835434d,     0xf8307169,
    0xf83562b1,     0xf8b98139,     0xf8a500d9,     0xf8b812ee,
    0xf8b32358,     0xf8af3057,     0xf8a650e7,     0xf8be41cf,
    0xf8bf70a7,     0xf8b46039,     0xf8f08232,     0xf8e0016f,
    0xf8e910f1,     0xf8e122f7,     0xf8f23061,     0xf8fb511f,
    0xf8e9417b,     0xf8f97063,     0xf8f06338,     0xf86683a2,
    0xf8770199,     0xf86912fd,     0xf87d2040,     0xf8733146,
    0xf871532d,     0xf8614337,     0xf87470da,     0xf86d6196,
    0xb8378378,     0xb8230287,     0xb82a12f5,     0xb829219a,
    0xb83a3377,     0xb82452ae,     0xb82a4120,     0xb82970cd,
    0xb82962bf,     0xb8ac817c,     0xb8a80180,     0xb8bd1027,
    0xb8bd233b,     0xb8bb3110,     0xb8ad53f2,     0xb8bc4300,
    0xb8bc71bc,     0xb8ae605d,     0xb8e8823c,     0xb8e4004a,
    0xb8e011dc,     0xb8e8208c,     0xb8e131b6,     0xb8f85286,
    0xb8ee408e,     0xb8fe71c2,     0xb8e262d2,     0xb8798239,
    0xb86400f3,     0xb873116f,     0xb877221d,     0xb87b3345,
    0xb87f501b,     0xb8764086,     0xb86d705e,     0xb873619a,

  };
// END  Generated code -- do not edit

  asm_check((unsigned int *)entry, insns, sizeof insns / sizeof insns[0]);

  {
    address PC = __ pc();
    __ ld1(v0, __ T16B, Address(r16));      // No offset
    __ ld1(v0, __ T8H, __ post(r16, 16));   // Post-index
    __ ld2(v0, v1, __ T8H, __ post(r24, 16 * 2));   // Post-index
    __ ld1(v0, __ T16B, __ post(r16, r17)); // Register post-index
    static const unsigned int vector_insns[] = {
       0x4c407200, // ld1   {v0.16b}, [x16]
       0x4cdf7600, // ld1   {v0.8h}, [x16], #16
       0x4cdf8700, // ld2   {v0.8h, v1.8h}, [x24], #32
       0x4cd17200, // ld1   {v0.16b}, [x16], x17
      };
    asm_check((unsigned int *)PC, vector_insns,
              sizeof vector_insns / sizeof vector_insns[0]);
  }
}
#endif // ASSERT

#undef __

void Assembler::emit_data64(jlong data,
                            relocInfo::relocType rtype,
                            int format) {
  if (rtype == relocInfo::none) {
    emit_int64(data);
  } else {
    emit_data64(data, Relocation::spec_simple(rtype), format);
  }
}

void Assembler::emit_data64(jlong data,
                            RelocationHolder const& rspec,
                            int format) {

  assert(inst_mark() != NULL, "must be inside InstructionMark");
  // Do not use AbstractAssembler::relocate, which is not intended for
  // embedded words.  Instead, relocate to the enclosing instruction.
  code_section()->relocate(inst_mark(), rspec, format);
  emit_int64(data);
}

extern "C" {
  void das(uint64_t start, int len) {
    ResourceMark rm;
    len <<= 2;
    if (len < 0)
      Disassembler::decode((address)start + len, (address)start);
    else
      Disassembler::decode((address)start, (address)start + len);
  }

  JNIEXPORT void das1(uintptr_t insn) {
    das(insn, 1);
  }
}

#define gas_assert(ARG1) assert(ARG1, #ARG1)

#define __ as->

void Address::lea(MacroAssembler *as, Register r) const {
  Relocation* reloc = _rspec.reloc();
  relocInfo::relocType rtype = (relocInfo::relocType) reloc->type();

  switch(_mode) {
  case base_plus_offset: {
    if (_offset == 0 && _base == r) // it's a nop
      break;
    if (_offset > 0)
      __ add(r, _base, _offset);
    else
      __ sub(r, _base, -_offset);
      break;
  }
  case base_plus_offset_reg: {
    __ add(r, _base, _index, _ext.op(), MAX2(_ext.shift(), 0));
    break;
  }
  case literal: {
    if (rtype == relocInfo::none)
      __ mov(r, target());
    else
      __ movptr(r, (uint64_t)target());
    break;
  }
  default:
    ShouldNotReachHere();
  }
}

void Assembler::adrp(Register reg1, const Address &dest, uintptr_t &byte_offset) {
  ShouldNotReachHere();
}

#undef __

#define starti Instruction_aarch64 do_not_use(this); set_current(&do_not_use)

  void Assembler::adr(Register Rd, address adr) {
    intptr_t offset = adr - pc();
    int offset_lo = offset & 3;
    offset >>= 2;
    starti;
    f(0, 31), f(offset_lo, 30, 29), f(0b10000, 28, 24), sf(offset, 23, 5);
    rf(Rd, 0);
  }

  void Assembler::_adrp(Register Rd, address adr) {
    uint64_t pc_page = (uint64_t)pc() >> 12;
    uint64_t adr_page = (uint64_t)adr >> 12;
    intptr_t offset = adr_page - pc_page;
    int offset_lo = offset & 3;
    offset >>= 2;
    starti;
    f(1, 31), f(offset_lo, 30, 29), f(0b10000, 28, 24), sf(offset, 23, 5);
    rf(Rd, 0);
  }

#undef starti

Address::Address(address target, relocInfo::relocType rtype) : _mode(literal){
  _is_lval = false;
  _target = target;
  switch (rtype) {
  case relocInfo::oop_type:
  case relocInfo::metadata_type:
    // Oops are a special case. Normally they would be their own section
    // but in cases like icBuffer they are literals in the code stream that
    // we don't have a section for. We use none so that we get a literal address
    // which is always patchable.
    break;
  case relocInfo::external_word_type:
    _rspec = external_word_Relocation::spec(target);
    break;
  case relocInfo::internal_word_type:
    _rspec = internal_word_Relocation::spec(target);
    break;
  case relocInfo::opt_virtual_call_type:
    _rspec = opt_virtual_call_Relocation::spec();
    break;
  case relocInfo::static_call_type:
    _rspec = static_call_Relocation::spec();
    break;
  case relocInfo::runtime_call_type:
    _rspec = runtime_call_Relocation::spec();
    break;
  case relocInfo::poll_type:
  case relocInfo::poll_return_type:
    _rspec = Relocation::spec_simple(rtype);
    break;
  case relocInfo::none:
    _rspec = RelocationHolder::none;
    break;
  default:
    ShouldNotReachHere();
    break;
  }
}

void Assembler::b(const Address &dest) {
  code_section()->relocate(pc(), dest.rspec());
  b(dest.target());
}

void Assembler::bl(const Address &dest) {
  code_section()->relocate(pc(), dest.rspec());
  bl(dest.target());
}

void Assembler::adr(Register r, const Address &dest) {
  code_section()->relocate(pc(), dest.rspec());
  adr(r, dest.target());
}

void Assembler::br(Condition cc, Label &L) {
  if (L.is_bound()) {
    br(cc, target(L));
  } else {
    L.add_patch_at(code(), locator());
    br(cc, pc());
  }
}

void Assembler::wrap_label(Label &L,
                                 Assembler::uncond_branch_insn insn) {
  if (L.is_bound()) {
    (this->*insn)(target(L));
  } else {
    L.add_patch_at(code(), locator());
    (this->*insn)(pc());
  }
}

void Assembler::wrap_label(Register r, Label &L,
                                 compare_and_branch_insn insn) {
  if (L.is_bound()) {
    (this->*insn)(r, target(L));
  } else {
    L.add_patch_at(code(), locator());
    (this->*insn)(r, pc());
  }
}

void Assembler::wrap_label(Register r, int bitpos, Label &L,
                                 test_and_branch_insn insn) {
  if (L.is_bound()) {
    (this->*insn)(r, bitpos, target(L));
  } else {
    L.add_patch_at(code(), locator());
    (this->*insn)(r, bitpos, pc());
  }
}

void Assembler::wrap_label(Label &L, prfop op, prefetch_insn insn) {
  if (L.is_bound()) {
    (this->*insn)(target(L), op);
  } else {
    L.add_patch_at(code(), locator());
    (this->*insn)(pc(), op);
  }
}

// An "all-purpose" add/subtract immediate, per ARM documentation:
// A "programmer-friendly" assembler may accept a negative immediate
// between -(2^24 -1) and -1 inclusive, causing it to convert a
// requested ADD operation to a SUB, or vice versa, and then encode
// the absolute value of the immediate as for uimm24.
void Assembler::add_sub_immediate(Register Rd, Register Rn, unsigned uimm, int op,
                                  int negated_op) {
  bool sets_flags = op & 1;   // this op sets flags
  union {
    unsigned u;
    int imm;
  };
  u = uimm;
  bool shift = false;
  bool neg = imm < 0;
  if (neg) {
    imm = -imm;
    op = negated_op;
  }
  assert(Rd != sp || imm % 16 == 0, "misaligned stack");
  if (imm >= (1 << 11)
      && ((imm >> 12) << 12 == imm)) {
    imm >>= 12;
    shift = true;
  }
  f(op, 31, 29), f(0b10001, 28, 24), f(shift, 23, 22), f(imm, 21, 10);

  // add/subtract immediate ops with the S bit set treat r31 as zr;
  // with S unset they use sp.
  if (sets_flags)
    zrf(Rd, 0);
  else
    srf(Rd, 0);

  srf(Rn, 5);
}

bool Assembler::operand_valid_for_add_sub_immediate(int64_t imm) {
  bool shift = false;
  uint64_t uimm = (uint64_t)uabs(imm);
  if (uimm < (1 << 12))
    return true;
  if (uimm < (1 << 24)
      && ((uimm >> 12) << 12 == uimm)) {
    return true;
  }
  return false;
}

bool Assembler::operand_valid_for_logical_immediate(bool is32, uint64_t imm) {
  return encode_logical_immediate(is32, imm) != 0xffffffff;
}

static uint64_t doubleTo64Bits(jdouble d) {
  union {
    jdouble double_value;
    uint64_t double_bits;
  };

  double_value = d;
  return double_bits;
}

bool Assembler::operand_valid_for_float_immediate(double imm) {
  // If imm is all zero bits we can use ZR as the source of a
  // floating-point value.
  if (doubleTo64Bits(imm) == 0)
    return true;

  // Otherwise try to encode imm then convert the encoded value back
  // and make sure it's the exact same bit pattern.
  unsigned result = encoding_for_fp_immediate(imm);
  return doubleTo64Bits(imm) == fp_immediate_for_encoding(result, true);
}

int AbstractAssembler::code_fill_byte() {
  return 0;
}

// n.b. this is implemented in subclass MacroAssembler
void Assembler::bang_stack_with_offset(int offset) { Unimplemented(); }


// and now the routines called by the assembler which encapsulate the
// above encode and decode functions

uint32_t
asm_util::encode_logical_immediate(bool is32, uint64_t imm)
{
  if (is32) {
    /* Allow all zeros or all ones in top 32-bits, so that
       constant expressions like ~1 are permitted. */
    if (imm >> 32 != 0 && imm >> 32 != 0xffffffff)
      return 0xffffffff;
    /* Replicate the 32 lower bits to the 32 upper bits.  */
    imm &= 0xffffffff;
    imm |= imm << 32;
  }

  return encoding_for_logical_immediate(imm);
}

unsigned Assembler::pack(double value) {
  float val = (float)value;
  unsigned result = encoding_for_fp_immediate(val);
  guarantee(unpack(result) == value,
            "Invalid floating-point immediate operand");
  return result;
}

// Packed operands for  Floating-point Move (immediate)

static float unpack(unsigned value) {
  union {
    unsigned ival;
    float val;
  };
  ival = fp_immediate_for_encoding(value, 0);
  return val;
}
